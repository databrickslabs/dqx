{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQX - Use as library demo\n",
    "\n",
    "In this demo we demonstrate how to create and apply a set of rules from YAML configuration. \n",
    "\n",
    "**Note.**\n",
    "This notebook can be executed without any modifications when using the `VS Code Databricks Extension`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install DQX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install databricks-labs-dqx\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from databricks.labs.dqx.engine import DQEngineCore, DQEngine\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from pyspark.sql import SparkSession, Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Test Data\n",
    "\n",
    "The result of this next step is `new_users_df`, which represents a dataframe of new users which requires quality validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DQX_demo_library\").getOrCreate()\n",
    "\n",
    "# Create a sample DataFrame representing your 'nations' table\n",
    "new_users_sample_data = [\n",
    "    Row(id=1, age=23, country='Germany'),\n",
    "    Row(id=2, age=30, country='France'),\n",
    "    Row(id=3, age=16, country='Germany'), # Invalid -> age - LT 18\n",
    "    Row(id=None,  age=29, country='France'), # Invalid -> id - NULL\n",
    "    Row(id=4,  age=29, country=''), # Invalid -> country - Empty\n",
    "    Row(id=5,  age=23, country='Italy'), # Invalid -> country - not in\n",
    "    Row(id=6,  age=123, country='France') # Invalid -> age - GT 120\n",
    "]\n",
    "\n",
    "new_users_df = spark.createDataFrame(new_users_sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demoing Functions\n",
    "- `is_not_null_and_not_empty`\n",
    "- `is_in_range`\n",
    "- `is_in_list`\n",
    "\n",
    "You can find documentation of all built-in quality [here](https://databrickslabs.github.io/dqx/docs/reference/quality_rules/).\n",
    "\n",
    "We are demonstrating creating and validating a set of `Quality Checks` defined declaratively using YAML.\n",
    "\n",
    "We can use `validate_checks` to verify that the definition is defined correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks_from_yaml = yaml.safe_load(\"\"\"\n",
    "- check:\n",
    "    function: is_not_null_and_not_empty\n",
    "    for_each_column:\n",
    "      - id\n",
    "      - age\n",
    "      - country\n",
    "    criticality: error\n",
    "- check:\n",
    "    function: is_in_range\n",
    "    for_each_column:\n",
    "      - age\n",
    "    criticality: warn\n",
    "    arguments:\n",
    "      min_limit: 18\n",
    "      max_limit: 120\n",
    "- check:\n",
    "    function: is_in_list\n",
    "    for_each_column:\n",
    "      - country\n",
    "    criticality: warn\n",
    "    arguments:\n",
    "      allowed:\n",
    "        - Germany\n",
    "        - France\n",
    "\"\"\")\n",
    "\n",
    "# Validate YAML checks\n",
    "status = DQEngine.validate_checks(checks_from_yaml)\n",
    "print(f\"Checks from YAML: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "### Setup `DQEngine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = WorkspaceClient()\n",
    "dq_engine = DQEngine(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Rules\n",
    "`apply_checks_by_metadata` results in one `DataFrame` with `_errors` and `_warnings` metadata columns added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = dq_engine.apply_checks_by_metadata(new_users_df, checks_from_yaml)\n",
    "validated_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Rules And Split\n",
    "`apply_checks_by_metadata_and_split` results in a `tuple[DataFrame, DataFrame]` with _errors and _warnings metadata columns added. The first DF contains valid records, and the second invalid/quarantined records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_records_df, invalid_records_df = dq_engine.apply_checks_by_metadata_and_split(new_users_df, checks_from_yaml)\n",
    "valid_records_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_records_df.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
