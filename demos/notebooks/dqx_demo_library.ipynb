{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQX - Use as library demo\n",
    "\n",
    "In this demo we demonstrate how to create and apply a set of rules from an object and from a YAML configuration. \n",
    "\n",
    "**Note.**\n",
    "This notebook can be executed without any modifications when using the `VS Code Databricks Extension`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install DQX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting databricks-labs-dqx\n",
       "  Obtaining dependency information for databricks-labs-dqx from https://files.pythonhosted.org/packages/62/02/dd1313073e0cdcaee1371d03a98038fd7e90cd48d76be6ef50b57de72587/databricks_labs_dqx-0.5.0-py3-none-any.whl.metadata\n",
       "  Downloading databricks_labs_dqx-0.5.0-py3-none-any.whl.metadata (3.4 kB)\n",
       "Collecting databricks-labs-blueprint<0.10,>=0.9.1 (from databricks-labs-dqx)\n",
       "  Obtaining dependency information for databricks-labs-blueprint<0.10,>=0.9.1 from https://files.pythonhosted.org/packages/73/f7/4e77bdcd83fb5e53d79526f4532dd05af53e5dcbb2c2854ae536baecf133/databricks_labs_blueprint-0.9.3-py3-none-any.whl.metadata\n",
       "  Downloading databricks_labs_blueprint-0.9.3-py3-none-any.whl.metadata (55 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/55.1 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.1/55.1 kB 2.5 MB/s eta 0:00:00\n",
       "\u001b[?25hCollecting databricks-labs-lsql<0.15,>=0.5 (from databricks-labs-dqx)\n",
       "  Obtaining dependency information for databricks-labs-lsql<0.15,>=0.5 from https://files.pythonhosted.org/packages/e0/67/bc65eed315c45bfeb2df1fb3204894c45f16bef34c4cbbebbb0c528f9d71/databricks_labs_lsql-0.14.2-py3-none-any.whl.metadata\n",
       "  Downloading databricks_labs_lsql-0.14.2-py3-none-any.whl.metadata (8.7 kB)\n",
       "Collecting databricks-sdk~=0.30 (from databricks-labs-dqx)\n",
       "  Obtaining dependency information for databricks-sdk~=0.30 from https://files.pythonhosted.org/packages/51/db/6d34604be92a163309cbf1e3aeb11ea464012cdc33fe11132ea1eff2f072/databricks_sdk-0.57.0-py3-none-any.whl.metadata\n",
       "  Downloading databricks_sdk-0.57.0-py3-none-any.whl.metadata (39 kB)\n",
       "Collecting databricks-labs-blueprint[yaml]>=0.4.2 (from databricks-labs-lsql<0.15,>=0.5->databricks-labs-dqx)\n",
       "  Obtaining dependency information for databricks-labs-blueprint[yaml]>=0.4.2 from https://files.pythonhosted.org/packages/3a/a2/7c581bf8dc2b6827103cc789e0aaeeef1d1c5e52d1cf4ccd71ca242563a3/databricks_labs_blueprint-0.11.0-py3-none-any.whl.metadata\n",
       "  Downloading databricks_labs_blueprint-0.11.0-py3-none-any.whl.metadata (55 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/55.1 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.1/55.1 kB 10.1 MB/s eta 0:00:00\n",
       "\u001b[?25hCollecting sqlglot>=22.3.1 (from databricks-labs-lsql<0.15,>=0.5->databricks-labs-dqx)\n",
       "  Obtaining dependency information for sqlglot>=22.3.1 from https://files.pythonhosted.org/packages/fc/1c/8c12a753150c508087302f116de3ce7bfdb81a58801c2a65bdf9675c5fdc/sqlglot-26.28.1-py3-none-any.whl.metadata\n",
       "  Downloading sqlglot-26.28.1-py3-none-any.whl.metadata (20 kB)\n",
       "Requirement already satisfied: requests<3,>=2.28.1 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk~=0.30->databricks-labs-dqx) (2.31.0)\n",
       "Requirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk~=0.30->databricks-labs-dqx) (2.31.0)\n",
       "INFO: pip is looking at multiple versions of databricks-labs-blueprint[yaml] to determine which version is compatible with other requirements. This could take a while.\n",
       "Collecting databricks-labs-blueprint[yaml]>=0.4.2 (from databricks-labs-lsql<0.15,>=0.5->databricks-labs-dqx)\n",
       "  Obtaining dependency information for databricks-labs-blueprint[yaml]>=0.4.2 from https://files.pythonhosted.org/packages/7e/51/fad6ce2e8143e8d68a10572ec86dbb770a8db4bcc28b58516acc770a64c0/databricks_labs_blueprint-0.10.2-py3-none-any.whl.metadata\n",
       "  Downloading databricks_labs_blueprint-0.10.2-py3-none-any.whl.metadata (55 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/55.1 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.1/55.1 kB 8.7 MB/s eta 0:00:00\n",
       "\u001b[?25h  Obtaining dependency information for databricks-labs-blueprint[yaml]>=0.4.2 from https://files.pythonhosted.org/packages/d0/5e/d1694c1421be2dc9b548815bd28c8cec98b1d7cddbaf2b98f74c28eaa160/databricks_labs_blueprint-0.10.1-py3-none-any.whl.metadata\n",
       "  Downloading databricks_labs_blueprint-0.10.1-py3-none-any.whl.metadata (55 kB)\n",
       "\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/55.1 kB ? eta -:--:--\n",
       "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.1/55.1 kB 7.7 MB/s eta 0:00:00\n",
       "\u001b[?25hRequirement already satisfied: pyyaml<7.0.0,>=6.0.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-labs-blueprint<0.10,>=0.9.1->databricks-labs-dqx) (6.0)\n",
       "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk~=0.30->databricks-labs-dqx) (5.3.3)\n",
       "Requirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk~=0.30->databricks-labs-dqx) (0.2.8)\n",
       "Requirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk~=0.30->databricks-labs-dqx) (4.9)\n",
       "Requirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk~=0.30->databricks-labs-dqx) (2.0.4)\n",
       "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk~=0.30->databricks-labs-dqx) (3.4)\n",
       "Requirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk~=0.30->databricks-labs-dqx) (1.26.16)\n",
       "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk~=0.30->databricks-labs-dqx) (2023.7.22)\n",
       "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk~=0.30->databricks-labs-dqx) (0.4.8)\n",
       "Downloading databricks_labs_dqx-0.5.0-py3-none-any.whl (72 kB)\n",
       "\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/72.0 kB ? eta -:--:--\n",
       "\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.0/72.0 kB 10.9 MB/s eta 0:00:00\n",
       "\u001b[?25hDownloading databricks_labs_blueprint-0.9.3-py3-none-any.whl (61 kB)\n",
       "\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/61.5 kB ? eta -:--:--\n",
       "\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 kB 11.1 MB/s eta 0:00:00\n",
       "\u001b[?25hDownloading databricks_labs_lsql-0.14.2-py3-none-any.whl (47 kB)\n",
       "\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/48.0 kB ? eta -:--:--\n",
       "\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.0/48.0 kB 6.5 MB/s eta 0:00:00\n",
       "\u001b[?25hDownloading databricks_sdk-0.57.0-py3-none-any.whl (733 kB)\n",
       "\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/733.8 kB ? eta -:--:--\n",
       "\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 733.8/733.8 kB 43.5 MB/s eta 0:00:00\n",
       "\u001b[?25hDownloading sqlglot-26.28.1-py3-none-any.whl (468 kB)\n",
       "\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/468.1 kB ? eta -:--:--\n",
       "\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.1/468.1 kB 24.9 MB/s eta 0:00:00\n",
       "\u001b[?25hInstalling collected packages: sqlglot, databricks-sdk, databricks-labs-blueprint, databricks-labs-lsql, databricks-labs-dqx\n",
       "  Attempting uninstall: databricks-sdk\n",
       "    Found existing installation: databricks-sdk 0.20.0\n",
       "    Not uninstalling databricks-sdk at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-fdc94e66-7be4-4080-8f6c-e188927e7e6d\n",
       "    Can't uninstall 'databricks-sdk'. No files were found to uninstall.\n",
       "Successfully installed databricks-labs-blueprint-0.9.3 databricks-labs-dqx-0.5.0 databricks-labs-lsql-0.14.2 databricks-sdk-0.57.0 sqlglot-26.28.1\n",
       "Note: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TypeError: Cannot read properties of undefined (reading 'fsPath')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install databricks-labs-dqx\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import yaml\n",
    "from databricks.labs.dqx.engine import DQEngineCore, DQEngine\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from pyspark.sql import SparkSession, Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Test Data\n",
    "\n",
    "The result of this next step is `new_users_df`, which represents a dataset of new users which requires quality validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"DQX_demo_library\").getOrCreate()\n",
    "\n",
    "# Create a sample DataFrame representing your 'nations' table\n",
    "new_users_sample_data = [\n",
    "    Row(id=1, age=23, country='Germany'),\n",
    "    Row(id=2, age=30, country='France'),\n",
    "    Row(id=3, age=16, country='Germany'), # Invalid -> age - LT 18\n",
    "    Row(id=None,  age=29, country='France'), # Invalid -> id - NULL\n",
    "    Row(id=4,  age=29, country=''), # Invalid -> country - Empty\n",
    "    Row(id=5,  age=23, country='Italy'), # Invalid -> country - not in\n",
    "    Row(id=6,  age=123, country='France') # Invalid -> age - GT 120\n",
    "]\n",
    "\n",
    "new_users_df = spark.createDataFrame(new_users_sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demoing Functions\n",
    "- is_not_null_and_not_empty\n",
    "- is_in_range\n",
    "- is_in_list\n",
    "Link to built-in quality checks - [check_funcs.py](https://github.com/databrickslabs/dqx/blob/98c3ef12d7b2ce3c1cc6c2bc3f9643a27876d817/src/databricks/labs/dqx/check_funcs.py)\n",
    "\n",
    "We are demonstrating 2 methods for creating a `Checks` array:\n",
    "- **checks_from_object**: Is a python array that can be casted to `list[DQRule]`\n",
    "- **checks_from_yaml**: yaml object that can directly be used by `DQEngine`\n",
    "\n",
    "Then we use `validate_checks` to make sure our configurations are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Checks from YAML: No errors found"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checks_from_yaml = yaml.safe_load(\"\"\"\n",
    "- check:\n",
    "    function: is_not_null_and_not_empty\n",
    "    for_each_column:\n",
    "      - id\n",
    "      - age\n",
    "      - country\n",
    "    criticality: error\n",
    "- check:\n",
    "    function: is_in_range\n",
    "    for_each_column:\n",
    "      - age\n",
    "    criticality: warn\n",
    "    arguments:\n",
    "      min_limit: 18\n",
    "      max_limit: 120\n",
    "- check:\n",
    "    function: is_in_list\n",
    "    for_each_column:\n",
    "      - country\n",
    "    criticality: warn\n",
    "    arguments:\n",
    "      allowed:\n",
    "        - Germany\n",
    "        - France\n",
    "\"\"\")\n",
    "\n",
    "# Validate YAML checks\n",
    "status = DQEngine.validate_checks(checks_from_yaml)\n",
    "print(f\"Checks from YAML: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "source": [
    "### Setup `DQEngine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "ws = WorkspaceClient()\n",
    "dq_engine = DQEngine(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply YAML Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+----+---+-------+--------------------+---------+\n",
       "|  id|age|country|             _errors|_warnings|\n",
       "+----+---+-------+--------------------+---------+\n",
       "|   1| 23|Germany|                NULL|     NULL|\n",
       "|   2| 30| France|                NULL|     NULL|\n",
       "|   3| 16|Germany|[{age_not_in_rang...|     NULL|\n",
       "|NULL| 29| France|[{id_is_null_or_e...|     NULL|\n",
       "|   4| 29|       |[{country_is_null...|     NULL|\n",
       "|   5| 23|  Italy|[{country_is_not_...|     NULL|\n",
       "|   6|123| France|[{age_not_in_rang...|     NULL|\n",
       "+----+---+-------+--------------------+---------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "validated_df = dq_engine.apply_checks_by_metadata(new_users_df, checks_from_yaml)\n",
    "validated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "yaml_rules_valid_rows, yaml_rules_invalid_rows = dq_engine.apply_checks_by_metadata_and_split(new_users_df, checks_from_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---+---+-------+\n",
       "| id|age|country|\n",
       "+---+---+-------+\n",
       "|  1| 23|Germany|\n",
       "|  2| 30| France|\n",
       "+---+---+-------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yaml_rules_valid_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+----+---+-------+--------------------+---------+\n",
       "|  id|age|country|             _errors|_warnings|\n",
       "+----+---+-------+--------------------+---------+\n",
       "|   3| 16|Germany|[{age_not_in_rang...|     NULL|\n",
       "|NULL| 29| France|[{id_is_null_or_e...|     NULL|\n",
       "|   4| 29|       |[{country_is_null...|     NULL|\n",
       "|   5| 23|  Italy|[{country_is_not_...|     NULL|\n",
       "|   6|123| France|[{age_not_in_rang...|     NULL|\n",
       "+----+---+-------+--------------------+---------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yaml_rules_invalid_rows.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
