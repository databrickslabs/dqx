{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DQX Anomaly Detection Demo\n",
        "\n",
        "This notebook shows three scenarios for `has_no_anomalies` using the new Spark ML IsolationForest pipeline:\n",
        "\n",
        "1) **Simple data, defaults** – quick start with auto-derived names/registry.\n",
        "2) **Structured data, tuned parameters** – demonstrate `AnomalyParams` and `IsolationForestConfig`.\n",
        "3) **Large data (~10M rows)** – train with sampling caps; notes on runtime/perf.\n",
        "\n",
        "> Requires Spark ≥ 3.5 / DBR ≥ 15.4 and `databricks-labs-dqx[anomaly]` installed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running in a clean cluster, install the anomaly extra\n",
        "# %pip install 'databricks-labs-dqx[anomaly]'\n",
        "\n",
        "from databricks.labs.dqx import anomaly\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import pyspark.sql.functions as F\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Simple data, defaults\n",
        "- Auto-derives `model_name` and `registry_table`\n",
        "- Uses default sampling (0.3), max_rows (1M), train_ratio (0.8)\n",
        "- Default score threshold: 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple synthetic data\n",
        "small_df = spark.createDataFrame(\n",
        "    [\n",
        "        (\"A\", 10.0, 1.0),\n",
        "        (\"A\", 11.0, 1.2),\n",
        "        (\"A\", 9.5, 0.9),\n",
        "        (\"B\", 50.0, 5.0),\n",
        "        (\"B\", 49.0, 4.8),\n",
        "        (\"B\", 52.0, 5.3),\n",
        "    ],\n",
        "    \"category string, amount double, quantity double\",\n",
        ")\n",
        "\n",
        "# Train with defaults (auto names, auto registry table)\n",
        "anomaly.train(\n",
        "    df=small_df,\n",
        "    columns=[\"amount\", \"quantity\"],\n",
        ")\n",
        "\n",
        "# Apply check\n",
        "checks = [\n",
        "    anomaly.has_no_anomalies(\n",
        "        columns=[\"amount\", \"quantity\"],\n",
        "        score_threshold=0.5,\n",
        "    )\n",
        "]\n",
        "\n",
        "# Just show scored rows for illustration\n",
        "from databricks.labs.dqx.anomaly.model_registry import AnomalyModelRegistry\n",
        "\n",
        "registry_table = None  # auto-derived same as training\n",
        "model_name = None      # auto-derived same as training\n",
        "\n",
        "# For demo, reload model and score\n",
        "# (Normally you would use DQEngine.apply_checks)\n",
        "\n",
        "loaded_model_name = model_name\n",
        "loaded_registry_table = registry_table\n",
        "\n",
        "# Derive names using helper (matches training auto-derivation)\n",
        "from databricks.labs.dqx.anomaly.trainer import _derive_model_name, _derive_registry_table\n",
        "\n",
        "active_model_name = loaded_model_name or _derive_model_name(small_df, [\"amount\", \"quantity\"])\n",
        "active_registry = loaded_registry_table or _derive_registry_table(small_df)\n",
        "\n",
        "active = AnomalyModelRegistry(small_df.sparkSession).get_active_model(active_registry, active_model_name)\n",
        "scored = mlflow.spark.load_model(active.model_uri).transform(small_df)\n",
        "scored.select(\"category\", \"amount\", \"quantity\", \"anomaly_score\").show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Structured data with AnomalyParams\n",
        "- Show tuned sampling and algorithm config\n",
        "- Explicit model/registry names for repeatability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from databricks.labs.dqx import anomaly\n",
        "\n",
        "adv_params = anomaly.AnomalyParams(\n",
        "    sample_fraction=0.4,\n",
        "    max_rows=500_000,\n",
        "    train_ratio=0.8,\n",
        "    algorithm_config=anomaly.IsolationForestConfig(\n",
        "        contamination=0.08,\n",
        "        num_trees=300,\n",
        "    ),\n",
        ")\n",
        "\n",
        "structured_df = spark.createDataFrame(\n",
        "    [(\"2024-01-01\", \"us\", 100.0, 2.0), (\"2024-01-02\", \"us\", 105.0, 2.2), (\"2024-01-01\", \"eu\", 90.0, 1.8)],\n",
        "    \"ds string, region string, amount double, quantity double\",\n",
        ")\n",
        "\n",
        "anomaly.train(\n",
        "    df=structured_df,\n",
        "    columns=[\"amount\", \"quantity\"],\n",
        "    model_name=\"orders_anomaly_custom\",\n",
        "    registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        "    params=adv_params,\n",
        ")\n",
        "\n",
        "checks = [\n",
        "    anomaly.has_no_anomalies(\n",
        "        columns=[\"amount\", \"quantity\"],\n",
        "        model=\"orders_anomaly_custom\",\n",
        "        registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        "        score_threshold=0.6,\n",
        "    )\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Large data (~10M rows)\n",
        "- Uses sampling caps to keep training tractable\n",
        "- Expect longer runtime; adjust `sample_fraction`/`max_rows` if needed\n",
        "- Demonstrates simple train + check\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Model Metrics and Recommended Thresholds\n",
        "- Query registry to view validation metrics\n",
        "- Use recommended threshold (F1-optimal)\n",
        "- View feature importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a model to examine metrics\n",
        "metrics_df = spark.createDataFrame(\n",
        "    [\n",
        "        (100.0, 2.0), (105.0, 2.2), (95.0, 1.8), (102.0, 2.1), (98.0, 1.9),\n",
        "        (500.0, 1.0),  # anomaly: high amount, low quantity\n",
        "    ],\n",
        "    \"amount double, quantity double\",\n",
        ")\n",
        "\n",
        "anomaly.train(\n",
        "    df=metrics_df,\n",
        "    columns=[\"amount\", \"quantity\"],\n",
        "    model_name=\"metrics_demo\",\n",
        "    registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        ")\n",
        "\n",
        "# Query metrics from registry\n",
        "metrics_query = spark.sql(\"\"\"\n",
        "    SELECT \n",
        "        model_name,\n",
        "        metrics['recommended_threshold'] as recommended_threshold,\n",
        "        metrics['threshold_50_precision'] as precision_at_50,\n",
        "        metrics['threshold_50_recall'] as recall_at_50,\n",
        "        metrics['threshold_50_f1'] as f1_at_50,\n",
        "        metrics['estimated_contamination'] as est_contamination,\n",
        "        feature_importance,\n",
        "        training_time\n",
        "    FROM catalog.schema.dqx_anomaly_models\n",
        "    WHERE model_name = 'metrics_demo' AND status = 'active'\n",
        "\"\"\")\n",
        "\n",
        "display(metrics_query)\n",
        "\n",
        "# Use recommended threshold in checks\n",
        "recommended_threshold = metrics_query.first()['recommended_threshold']\n",
        "print(f\"Using recommended threshold: {recommended_threshold}\")\n",
        "\n",
        "checks = [\n",
        "    anomaly.has_no_anomalies(\n",
        "        columns=[\"amount\", \"quantity\"],\n",
        "        model=\"metrics_demo\",\n",
        "        registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        "        score_threshold=recommended_threshold,\n",
        "    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Feature Contributions for Explainability\n",
        "- Enable `include_contributions=True`\n",
        "- See which columns drove each anomaly score\n",
        "- Use with DQEngine for complete workflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data with clear anomalies\n",
        "explainability_df = spark.createDataFrame(\n",
        "    [\n",
        "        (100.0, 2.0, 0.10),  # normal\n",
        "        (105.0, 2.2, 0.12),  # normal\n",
        "        (95.0, 1.8, 0.08),   # normal\n",
        "        (9999.0, 1.0, 0.95), # anomaly: very high amount, high discount\n",
        "    ],\n",
        "    \"amount double, quantity double, discount double\",\n",
        ")\n",
        "\n",
        "# Train\n",
        "anomaly.train(\n",
        "    df=explainability_df,\n",
        "    columns=[\"amount\", \"quantity\", \"discount\"],\n",
        "    model_name=\"explainability_demo\",\n",
        "    registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        ")\n",
        "\n",
        "# Apply check with contributions\n",
        "from databricks.labs.dqx.engine import DQEngine\n",
        "from databricks.sdk import WorkspaceClient\n",
        "\n",
        "dq_engine = DQEngine(WorkspaceClient())\n",
        "\n",
        "checks = [\n",
        "    anomaly.has_no_anomalies(\n",
        "        columns=[\"amount\", \"quantity\", \"discount\"],\n",
        "        model=\"explainability_demo\",\n",
        "        registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        "        score_threshold=0.5,\n",
        "        include_contributions=True,  # Enable feature contributions\n",
        "    )\n",
        "]\n",
        "\n",
        "result_df = dq_engine.apply_checks_by_metadata(explainability_df, checks)\n",
        "\n",
        "# Show results with contributions\n",
        "display(result_df.select(\"amount\", \"quantity\", \"discount\", \"anomaly_score\", \"anomaly_contributions\"))\n",
        "\n",
        "# Filter to anomalies only\n",
        "anomalous_rows = result_df.filter(F.col(\"anomaly_score\") > 0.5)\n",
        "display(anomalous_rows.select(\"amount\", \"quantity\", \"discount\", \"anomaly_score\", \"anomaly_contributions\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Drift Detection and Retraining\n",
        "- Train on \"old\" distribution\n",
        "- Check on \"shifted\" distribution\n",
        "- Observe drift warnings with retrain recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Train on \"old\" distribution (mean ~100)\n",
        "old_distribution_df = spark.createDataFrame(\n",
        "    [(100.0 + i * 2.0, 2.0) for i in range(50)],\n",
        "    \"amount double, quantity double\",\n",
        ")\n",
        "\n",
        "anomaly.train(\n",
        "    df=old_distribution_df,\n",
        "    columns=[\"amount\", \"quantity\"],\n",
        "    model_name=\"drift_demo\",\n",
        "    registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        ")\n",
        "\n",
        "# Simulate \"new\" distribution with significant shift (mean ~500)\n",
        "new_distribution_df = spark.createDataFrame(\n",
        "    [(500.0 + i * 2.0, 5.0) for i in range(20)],\n",
        "    \"amount double, quantity double\",\n",
        ")\n",
        "\n",
        "# Apply check with drift detection enabled\n",
        "checks = [\n",
        "    anomaly.has_no_anomalies(\n",
        "        columns=[\"amount\", \"quantity\"],\n",
        "        model=\"drift_demo\",\n",
        "        registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        "        score_threshold=0.5,\n",
        "        drift_threshold=3.0,  # Enable drift detection (default threshold)\n",
        "    )\n",
        "]\n",
        "\n",
        "# Capture warnings\n",
        "with warnings.catch_warnings(record=True) as w:\n",
        "    warnings.simplefilter(\"always\")\n",
        "    result_df = dq_engine.apply_checks_by_metadata(new_distribution_df, checks)\n",
        "    \n",
        "    # Display warnings\n",
        "    for warning in w:\n",
        "        print(f\"WARNING: {warning.message}\")\n",
        "\n",
        "# Show results\n",
        "display(result_df.select(\"amount\", \"quantity\", \"anomaly_score\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Quarantine Workflow\n",
        "- Split valid and invalid rows\n",
        "- Save to separate tables (valid and quarantine)\n",
        "- Quarantine includes anomaly scores and contributions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from databricks.labs.dqx.config import OutputConfig\n",
        "\n",
        "# Data with mix of normal and anomalous rows\n",
        "quarantine_df = spark.createDataFrame(\n",
        "    [\n",
        "        (1, 100.0, 2.0, 0.10),  # normal\n",
        "        (2, 105.0, 2.2, 0.12),  # normal\n",
        "        (3, 95.0, 1.8, 0.08),   # normal\n",
        "        (4, 9999.0, 1.0, 0.95), # anomaly\n",
        "        (5, 102.0, 2.1, 0.11),  # normal\n",
        "        (6, 5000.0, 0.5, 0.90), # anomaly\n",
        "    ],\n",
        "    \"id int, amount double, quantity double, discount double\",\n",
        ")\n",
        "\n",
        "# Train\n",
        "anomaly.train(\n",
        "    df=quarantine_df.filter(\"id <= 3\"),  # train on normal rows only\n",
        "    columns=[\"amount\", \"quantity\", \"discount\"],\n",
        "    model_name=\"quarantine_demo\",\n",
        "    registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        ")\n",
        "\n",
        "# Apply check with contributions\n",
        "checks = [\n",
        "    anomaly.has_no_anomalies(\n",
        "        columns=[\"amount\", \"quantity\", \"discount\"],\n",
        "        model=\"quarantine_demo\",\n",
        "        registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        "        score_threshold=0.5,\n",
        "        include_contributions=True,\n",
        "    )\n",
        "]\n",
        "\n",
        "# Split valid and invalid\n",
        "valid_df, invalid_df = dq_engine.apply_checks_by_metadata_and_split(quarantine_df, checks)\n",
        "\n",
        "print(f\"Valid rows: {valid_df.count()}\")\n",
        "print(f\"Invalid (anomalous) rows: {invalid_df.count()}\")\n",
        "\n",
        "# Show quarantined rows with anomaly details\n",
        "display(invalid_df.select(\n",
        "    \"id\", \"amount\", \"quantity\", \"discount\",\n",
        "    \"anomaly_score\", \"anomaly_contributions\",\n",
        "    \"dqx_check_name\", \"dqx_error_message\"\n",
        "))\n",
        "\n",
        "# Save to tables (commented out to avoid creating tables in demo)\n",
        "# dq_engine.save_results_in_table(\n",
        "#     output_df=valid_df,\n",
        "#     quarantine_df=invalid_df,\n",
        "#     output_config=OutputConfig(location=\"catalog.schema.valid_orders\"),\n",
        "#     quarantine_config=OutputConfig(location=\"catalog.schema.quarantine_orders\"),\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate ~10M rows with simple numeric columns\n",
        "large_df = spark.range(0, 10_000_000).select(\n",
        "    F.col(\"id\").alias(\"row_id\"),\n",
        "    (F.col(\"id\") % 1000).cast(\"double\").alias(\"amount\"),\n",
        "    (F.col(\"id\") % 50).cast(\"double\").alias(\"quantity\"),\n",
        ")\n",
        "\n",
        "# Train with defaults (sampling and max_rows will cap workload)\n",
        "anomaly.train(\n",
        "    df=large_df,\n",
        "    columns=[\"amount\", \"quantity\"],\n",
        "    model_name=\"large_anomaly_demo\",\n",
        "    registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        ")\n",
        "\n",
        "checks = [\n",
        "    anomaly.has_no_anomalies(\n",
        "        columns=[\"amount\", \"quantity\"],\n",
        "        model=\"large_anomaly_demo\",\n",
        "        registry_table=\"catalog.schema.dqx_anomaly_models\",\n",
        "        score_threshold=0.5,\n",
        "    )\n",
        "]\n",
        "\n",
        "# Example: run transform to materialize scores (normally use DQEngine)\n",
        "from databricks.labs.dqx.anomaly.model_registry import AnomalyModelRegistry\n",
        "active = AnomalyModelRegistry(spark).get_active_model(\"catalog.schema.dqx_anomaly_models\", \"large_anomaly_demo\")\n",
        "scored_large = mlflow.spark.load_model(active.model_uri).transform(large_df.limit(1000))\n",
        "scored_large.select(\"row_id\", \"anomaly_score\").show(5)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
