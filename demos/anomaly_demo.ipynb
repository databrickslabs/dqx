{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¯ DQX Anomaly Detection Demo\n",
        "\n",
        "This notebook demonstrates **ML-based anomaly detection** in DQX, from basic 101 usage to advanced features.\n",
        "\n",
        "## ðŸ“š What You'll Learn\n",
        "\n",
        "1. **Basic 101**: Train a model and detect anomalies\n",
        "2. **Understanding Scores**: Interpret anomaly scores and thresholds\n",
        "3. **Feature Importance**: Which columns contribute to anomalies\n",
        "4. **Drift Detection**: Monitor when models need retraining\n",
        "5. **Advanced**: Ensemble models and temporal features\n",
        "\n",
        "## ðŸ”§ Prerequisites\n",
        "\n",
        "- Databricks Runtime 13.3+ (for anomaly support)\n",
        "- DQX installed with `anomaly` extras: `%pip install databricks-labs-dqx[anomaly]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "\n",
        "from databricks.labs.dqx.anomaly import train, has_no_anomalies, AnomalyParams, IsolationForestConfig\n",
        "from databricks.labs.dqx.engine import DQEngine\n",
        "from databricks.labs.dqx.rule import DQDatasetRule\n",
        "from databricks.sdk import WorkspaceClient\n",
        "\n",
        "# Initialize\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "ws = WorkspaceClient()\n",
        "dq_engine = DQEngine(ws)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"âœ… Setup complete!\")\n",
        "print(f\"   Spark version: {spark.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Part 0: Auto-Discovery & Segments (Recommended) ðŸš€\n",
        "\n",
        "**Zero-config anomaly detection** with automatic column and segment detection.\n",
        "\n",
        "### Why Auto-Discovery?\n",
        "- No manual column selection needed\n",
        "- Automatically finds good segmentation (regions, categories, etc.)\n",
        "- One-liner training for most use cases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate multi-region e-commerce data\n",
        "# Each region has different typical patterns\n",
        "data = []\n",
        "for region in [\"US\", \"EU\", \"APAC\"]:\n",
        "    base_amount = 100 if region == \"US\" else (150 if region == \"EU\" else 120)\n",
        "    base_discount = 0.1 if region == \"US\" else (0.15 if region == \"EU\" else 0.12)\n",
        "    \n",
        "    for i in range(300):  # 300 records per region\n",
        "        amount = base_amount + np.random.normal(0, 10)\n",
        "        discount_rate = base_discount + np.random.normal(0, 0.02)\n",
        "        quantity = np.random.randint(1, 10)\n",
        "        \n",
        "        data.append((\n",
        "            region,\n",
        "            f\"product_{np.random.randint(1, 50)}\",\n",
        "            round(amount, 2),\n",
        "            round(discount_rate, 3),\n",
        "            quantity\n",
        "        ))\n",
        "\n",
        "df = spark.createDataFrame(data, \"region string, product_id string, amount double, discount_rate double, quantity int\")\n",
        "\n",
        "# Save to table\n",
        "df.write.mode(\"overwrite\").saveAsTable(\"demo.orders_multiregion\")\n",
        "\n",
        "print(f\"âœ… Generated {df.count()} multi-region orders\")\n",
        "df.groupBy(\"region\").count().orderBy(\"region\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zero-config training: auto-discovers columns and segments!\n",
        "model_uri = train(df=spark.table(\"demo.orders_multiregion\"))\n",
        "\n",
        "# DQX will print:\n",
        "# \"Auto-selected 3 columns: [amount, discount_rate, quantity]\"\n",
        "# \"Auto-detected 1 segment column: [region] (3 total segments)\"\n",
        "# \"Training segment 1/3: region=APAC\"\n",
        "# \"Training segment 2/3: region=EU\"\n",
        "# \"Training segment 3/3: region=US\"\n",
        "\n",
        "print(\"\\nâœ… Models trained successfully!\")\n",
        "print(f\"Model URI: {model_uri}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score new data - auto-infers columns and segment_by from model!\n",
        "test_data = [\n",
        "    (\"US\", \"product_10\", 105.0, 0.11, 5),     # Normal US order\n",
        "    (\"US\", \"product_20\", 500.0, 0.50, 100),   # Anomaly: unusual for US\n",
        "    (\"EU\", \"product_30\", 155.0, 0.16, 4),     # Normal EU order\n",
        "    (\"EU\", \"product_40\", 50.0, 0.01, 1),      # Anomaly: unusual for EU\n",
        "    (\"APAC\", \"product_50\", 118.0, 0.13, 6),   # Normal APAC order\n",
        "]\n",
        "\n",
        "test_df = spark.createDataFrame(\n",
        "    test_data,\n",
        "    \"region string, product_id string, amount double, discount_rate double, quantity int\"\n",
        ")\n",
        "\n",
        "# Scoring automatically uses the correct regional model for each row!\n",
        "checks = [\n",
        "    has_no_anomalies()  # Zero config - infers everything from trained model!\n",
        "]\n",
        "\n",
        "result = dq_engine.apply_checks(test_df, checks)\n",
        "\n",
        "# Show results\n",
        "print(\"\\nðŸŽ¯ Anomaly Scores (by region-specific models):\")\n",
        "result.select(\"region\", \"amount\", \"discount_rate\", \"quantity\", \"anomaly_score\").orderBy(\"region\").show(truncate=False)\n",
        "\n",
        "# Count anomalies\n",
        "anomaly_count = result.filter(F.col(\"anomaly_score\") > 0.5).count()\n",
        "print(f\"\\nâš ï¸  Detected {anomaly_count} anomalies out of {result.count()} records\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸŽ‰ Key Benefits of Auto-Discovery\n",
        "\n",
        "1. **Zero Configuration**: No manual column selection needed\n",
        "2. **Segment-Aware**: Automatically trains separate models per region/category\n",
        "3. **Automatic Inference**: Scoring knows which segment model to use per row\n",
        "4. **Scalable**: Works with any number of segments (auto-warns if >50)\n",
        "\n",
        "**What happened behind the scenes:**\n",
        "- DQX analyzed your data and selected numeric columns with variance\n",
        "- Identified `region` as a good segment candidate (3 distinct values, >1000 rows per segment)\n",
        "- Trained 3 separate models (US, EU, APAC) with regional baselines\n",
        "- During scoring, each row was scored by its region-specific model\n",
        "\n",
        "**For manual control**, you can still specify columns and segments explicitly (see Part 1 below).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ“– Part 1: Basic 101 - Your First Anomaly Detection\n",
        "\n",
        "**Scenario**: You're monitoring API response times and request volumes. You want to automatically detect unusual patterns.\n",
        "\n",
        "**The Problem**: Setting static thresholds (e.g., \"response_time > 500ms\") is brittle:\n",
        "- Thresholds vary by time of day, day of week\n",
        "- Multivariate anomalies are hard to catch (high latency + low volume might indicate an attack)\n",
        "\n",
        "**The Solution**: ML-based anomaly detection learns \"normal\" behavior and flags deviations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate sample API monitoring data (training set - normal behavior)\n",
        "n_normal = 500\n",
        "\n",
        "normal_response_times = np.clip(np.random.gamma(shape=2, scale=50, size=n_normal), 10, 300)\n",
        "normal_request_volumes = np.clip(np.random.normal(100, 15, size=n_normal), 50, 150)\n",
        "\n",
        "train_data = [\n",
        "    (float(rt), float(rv)) \n",
        "    for rt, rv in zip(normal_response_times, normal_request_volumes)\n",
        "]\n",
        "\n",
        "train_df = spark.createDataFrame(train_data, schema=\"response_time_ms double, request_volume double\")\n",
        "\n",
        "print(f\"âœ… Generated {train_df.count()} training records\")\n",
        "print(\"\\nðŸ“Š Sample of normal behavior:\")\n",
        "train_df.select(\n",
        "    F.round(\"response_time_ms\", 1).alias(\"response_time_ms\"),\n",
        "    F.round(\"request_volume\", 1).alias(\"request_volume\")\n",
        ").show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Train the Model\n",
        "\n",
        "Training is simple - DQX handles all the complexity:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train anomaly detection model\n",
        "model_uri = train(\n",
        "    df=train_df,\n",
        "    columns=[\"response_time_ms\", \"request_volume\"],\n",
        "    model_name=\"api_monitoring_demo\",\n",
        "    registry_table=\"main.default.api_anomaly_models\"\n",
        ")\n",
        "\n",
        "print(f\"âœ… Model trained successfully!\")\n",
        "print(f\"   Model URI: {model_uri}\")\n",
        "print(f\"   Registry: main.default.api_anomaly_models\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Score New Data\n",
        "\n",
        "Now let's create some test data with both normal and anomalous patterns:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate test data with anomalies\n",
        "test_data = [\n",
        "    # Normal data points\n",
        "    (100.0, 105.0, \"normal\"),\n",
        "    (95.0, 98.0, \"normal\"),\n",
        "    (110.0, 102.0, \"normal\"),\n",
        "    # Anomalies: High latency + Normal volume\n",
        "    (450.0, 100.0, \"high_latency\"),\n",
        "    # Anomalies: Normal latency + Very low volume (potential DDoS)\n",
        "    (100.0, 20.0, \"low_volume_attack\"),\n",
        "    # Anomalies: Both high\n",
        "    (480.0, 180.0, \"system_overload\"),\n",
        "]\n",
        "\n",
        "test_df = spark.createDataFrame(test_data, schema=\"response_time_ms double, request_volume double, label string\")\n",
        "\n",
        "print(\"ðŸ“Š Test data (mixed normal + anomalies):\")\n",
        "test_df.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply anomaly detection check\n",
        "checks = [\n",
        "    DQDatasetRule(\n",
        "        criticality=\"error\",\n",
        "        check_func=has_no_anomalies,\n",
        "        check_func_kwargs={\n",
        "            \"columns\": [\"response_time_ms\", \"request_volume\"],\n",
        "            \"model\": \"api_monitoring_demo\",\n",
        "            \"registry_table\": \"main.default.api_anomaly_models\",\n",
        "            \"score_threshold\": 0.6,  # Adjust based on your tolerance\n",
        "        }\n",
        "    )\n",
        "]\n",
        "\n",
        "result_df = dq_engine.apply_checks(test_df, checks)\n",
        "\n",
        "# Show results with anomaly scores\n",
        "print(\"ðŸ“Š Results with anomaly scores:\")\n",
        "result_df.select(\n",
        "    F.round(\"response_time_ms\", 1).alias(\"response_time\"),\n",
        "    F.round(\"request_volume\", 1).alias(\"volume\"),\n",
        "    \"label\",\n",
        "    F.round(\"anomaly_score\", 3).alias(\"anomaly_score\"),\n",
        "    F.size(\"_errors\").alias(\"error_count\")\n",
        ").orderBy(F.desc(\"anomaly_score\")).show(truncate=False)\n",
        "\n",
        "print(\"\\nðŸ’¡ Interpretation:\")\n",
        "print(\"   - Scores > 0.6: Flagged as anomalies\")\n",
        "print(\"   - Scores < 0.6: Considered normal\")\n",
        "print(\"   - Higher scores = more unusual\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ“Š Part 2: Understanding Scores and Thresholds\n",
        "\n",
        "**Key Concepts**:\n",
        "- `anomaly_score`: Higher = more unusual (0 = very normal, 1+ = highly anomalous)\n",
        "- `score_threshold`: The cutoff for flagging anomalies (typically 0.5-0.7)\n",
        "\n",
        "**Choosing the Right Threshold**:\n",
        "- **Lower (0.3-0.5)**: More sensitive, catches more anomalies (higher false positives)\n",
        "- **Medium (0.5-0.7)**: Balanced approach (recommended starting point)\n",
        "- **Higher (0.7-0.9)**: Only flag extreme anomalies (fewer false positives)\n",
        "\n",
        "Let's see the model's recommended threshold based on validation data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the model registry for recommended threshold\n",
        "registry_df = spark.table(\"main.default.api_anomaly_models\")\n",
        "\n",
        "print(\"ðŸ“Š Model Metrics and Recommendations:\")\n",
        "registry_df.select(\n",
        "    \"model_name\",\n",
        "    \"training_time\",\n",
        "    F.round(F.col(\"metrics.recommended_threshold\"), 3).alias(\"recommended_threshold\"),\n",
        "    F.round(F.col(\"metrics.recommended_threshold_f1\"), 3).alias(\"f1_score\"),\n",
        "    F.round(F.col(\"metrics.score_mean\"), 3).alias(\"avg_score\"),\n",
        "    F.round(F.col(\"metrics.estimated_contamination\"), 3).alias(\"anomaly_rate\")\n",
        ").show(truncate=False)\n",
        "\n",
        "print(\"\\nðŸ’¡ Tips:\")\n",
        "print(\"   - Use 'recommended_threshold' as your starting point\")\n",
        "print(\"   - F1 score shows the balance between precision and recall\")\n",
        "print(\"   - Adjust based on your tolerance for false positives/negatives\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ” Part 3: Feature Importance - What Matters Most?\n",
        "\n",
        "DQX automatically computes **feature importance** during training to show which columns contribute most to anomaly detection:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract feature importance from the model registry\n",
        "print(\"ðŸ“Š Feature Importance (which columns matter most):\")\n",
        "registry_df.select(\n",
        "    \"model_name\",\n",
        "    \"feature_importance\"\n",
        ").show(truncate=False)\n",
        "\n",
        "# Convert to readable format\n",
        "importance = registry_df.select(\"feature_importance\").first()[\"feature_importance\"]\n",
        "if importance:\n",
        "    print(\"\\nðŸŽ¯ Feature Importance Rankings:\")\n",
        "    sorted_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
        "    for i, (feature, score) in enumerate(sorted_features, 1):\n",
        "        bar = \"â–ˆ\" * int(score * 50)\n",
        "        print(f\"   {i}. {feature:25} {bar} {score:.3f}\")\n",
        "    \n",
        "    print(\"\\nðŸ’¡ Interpretation:\")\n",
        "    print(\"   - Higher scores = more important for detecting anomalies\")\n",
        "    print(\"   - Focus monitoring efforts on high-importance features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ”„ Part 4: Drift Detection - When to Retrain?\n",
        "\n",
        "**The Problem**: Data distributions change over time:\n",
        "- API patterns evolve (new features, traffic patterns)\n",
        "- Infrastructure upgrades change baselines\n",
        "- Models become stale and less accurate\n",
        "\n",
        "**The Solution**: DQX automatically detects **data drift** and warns you when retraining is needed.\n",
        "\n",
        "Let's simulate shifted data and see drift detection in action:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate data after infrastructure upgrade (everything is 20% faster now)\n",
        "drifted_response_times = normal_response_times * 0.8  # 20% improvement\n",
        "drifted_volumes = normal_request_volumes * 1.3  # 30% more traffic\n",
        "\n",
        "drifted_data = [\n",
        "    (float(rt), float(rv)) \n",
        "    for rt, rv in zip(drifted_response_times[:100], drifted_volumes[:100])\n",
        "]\n",
        "\n",
        "drifted_df = spark.createDataFrame(drifted_data, schema=\"response_time_ms double, request_volume double\")\n",
        "\n",
        "print(\"ðŸ“Š Drifted data (after infrastructure upgrade):\")\n",
        "print(f\"   Original mean response_time: {normal_response_times.mean():.1f}ms\")\n",
        "print(f\"   New mean response_time:      {drifted_response_times[:100].mean():.1f}ms\")\n",
        "print(f\"   Original mean volume:        {normal_request_volumes.mean():.1f}\")\n",
        "print(f\"   New mean volume:             {drifted_volumes[:100].mean():.1f}\")\n",
        "\n",
        "# Apply checks on drifted data - DQX will warn about drift\n",
        "result_drift = dq_engine.apply_checks(drifted_df.limit(5), checks)\n",
        "\n",
        "print(\"\\nâœ… Check the warnings above! DQX detected drift and recommended retraining.\")\n",
        "print(\"\\nðŸ’¡ When you see drift warnings:\")\n",
        "print(\"   - Review if the distribution change is expected (e.g., infrastructure upgrade)\")\n",
        "print(\"   - Retrain the model on recent data: anomaly.train(df=new_data, ...)\")\n",
        "print(\"   - Or disable drift detection: drift_threshold=None\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸš€ Part 5: Advanced Features\n",
        "\n",
        "### Ensemble Models for Better Accuracy\n",
        "\n",
        "Train multiple models and average their predictions for more robust anomaly detection:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train an ensemble model (5 models with different random seeds)\n",
        "ensemble_params = AnomalyParams(\n",
        "    ensemble_size=3,  # Train 3 models\n",
        "    algorithm_config=IsolationForestConfig(\n",
        "        contamination=0.1,  # Expect 10% anomalies\n",
        "        num_trees=100  # Trees per model\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"ðŸ”„ Training ensemble model (this takes a bit longer)...\")\n",
        "ensemble_uri = train(\n",
        "    df=train_df,\n",
        "    columns=[\"response_time_ms\", \"request_volume\"],\n",
        "    model_name=\"api_monitoring_ensemble\",\n",
        "    registry_table=\"main.default.api_anomaly_models\",\n",
        "    params=ensemble_params\n",
        ")\n",
        "\n",
        "print(f\"âœ… Ensemble model trained!\")\n",
        "print(f\"\\nðŸ’¡ Benefits of ensemble:\")\n",
        "print(\"   - More robust to outliers\")\n",
        "print(\"   - Better generalization\")\n",
        "print(\"   - Provides confidence intervals (anomaly_score_std)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸŽ“ Summary & Next Steps\n",
        "\n",
        "### What You Learned\n",
        "\n",
        "âœ… **Basic 101**: Train and score anomalies in 3 lines of code  \n",
        "âœ… **Thresholds**: Interpret scores and choose the right cutoff  \n",
        "âœ… **Feature Importance**: Understand which columns matter most  \n",
        "âœ… **Drift Detection**: Automatic warnings when models need retraining  \n",
        "âœ… **Advanced**: Ensemble models for production use  \n",
        "\n",
        "### Real-World Use Cases\n",
        "\n",
        "1. **Fraud Detection**: Credit card transactions, insurance claims\n",
        "2. **Infrastructure Monitoring**: Server metrics, API performance, network traffic\n",
        "3. **Manufacturing**: Sensor data, equipment failures, quality control\n",
        "4. **Security**: Login patterns, access logs, threat detection\n",
        "5. **Business Metrics**: Sales patterns, user behavior, KPI monitoring\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Try with Your Data**: Replace the sample data with your actual tables\n",
        "2. **Integrate with Workflows**: Use `AnomalyTrainerWorkflow` for scheduled retraining\n",
        "3. **Combine with Other Checks**: Use alongside traditional DQX rules\n",
        "4. **Explore Temporal Features**: Add time-based patterns (hour, day_of_week, etc.)\n",
        "5. **Read the Docs**: See the full guide at [DQX Documentation](https://databrickslabs.github.io/dqx/)\n",
        "\n",
        "### ðŸ”— Additional Resources\n",
        "\n",
        "- **Documentation**: `docs/dqx/docs/guide/anomaly_detection.mdx`\n",
        "- **API Reference**: `docs/dqx/docs/reference/quality_checks.mdx`\n",
        "- **More Examples**: `demos/anomaly_demo_standalone.py`\n",
        "\n",
        "---\n",
        "\n",
        "**Questions?** Open an issue on the [DQX GitHub repo](https://github.com/databrickslabs/dqx)!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
