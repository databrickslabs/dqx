{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè• Pharmaceutical Field Force Effectiveness - Anomaly Detection Demo\n",
    "\n",
    "## Business Context\n",
    "\n",
    "**Scenario**: Monitor sales rep performance across regions to detect unusual patterns:\n",
    "- üí∞ Expense fraud or policy violations\n",
    "- üìâ Territory coverage issues and productivity gaps\n",
    "- üö® Unrealistic prescription claims\n",
    "- üìö Training needs identification\n",
    "\n",
    "**Data**: Sales rep daily activity with calls, prescriptions, samples, expenses across US, EU, APAC\n",
    "\n",
    "## What You'll Learn (45 min comprehensive demo)\n",
    "\n",
    "1. **Auto-Discovery** - Zero-config vs manual tuning\n",
    "2. **Segment-Based Monitoring** - Regional baselines (US vs EU vs APAC)\n",
    "3. **Parameter Tuning** - Contamination, hyperparameters, model comparison\n",
    "4. **Feature Contributions** - SHAP-based root cause analysis\n",
    "5. **Drift Detection** - When to retrain models\n",
    "6. **Multi-Type Features** - Numeric, categorical, datetime, boolean\n",
    "7. **Production Integration** - DQEngine, YAML, quarantine workflows\n",
    "\n",
    "---\n",
    "\n",
    "**üìã Table of Contents:**\n",
    "- Section 1: Setup & Realistic Data (5 min)\n",
    "- Section 2: Auto-Discovery & Manual Tuning (12 min)\n",
    "- Section 3: Segment-Based Monitoring (8 min)\n",
    "- Section 4: Feature Contributions & Root Cause (8 min)\n",
    "- Section 5: Drift Detection & Retraining (6 min)\n",
    "- Section 6: Production Integration (6 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Setup & Data Generation (5 min)\n",
    "\n",
    "First, install DQX with anomaly support if not already installed:\n",
    "```bash\n",
    "%pip install databricks-labs-dqx[anomaly]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from databricks.labs.dqx.anomaly import train, has_no_anomalies, AnomalyParams, IsolationForestConfig\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.labs.dqx.check_funcs import is_not_null, is_in_range\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "# Initialize\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "ws = WorkspaceClient()\n",
    "dq_engine = DQEngine(ws)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"   Spark version: {spark.version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Realistic Sales Rep Activity Data\n",
    "\n",
    "We'll create 1000 rows of daily sales rep activity with:\n",
    "- **Mixed data types**: Numeric, categorical, datetime, boolean\n",
    "- **Regional patterns**: Different baselines for US (high expenses), EU (moderate), APAC (high volume)\n",
    "- **Injected anomalies**: ~5% anomalous records (expense fraud, low productivity, unrealistic prescriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sales rep activity data with realistic patterns\n",
    "def generate_field_force_data(num_rows=1000, anomaly_rate=0.05):\n",
    "    \"\"\"Generate pharmaceutical field force activity data.\"\"\"\n",
    "    data = []\n",
    "    regions = [\"US\", \"EU\", \"APAC\"]\n",
    "    call_types = [\"promotional\", \"educational\", \"follow_up\"]\n",
    "    \n",
    "    # Regional baseline patterns (realistic differences)\n",
    "    regional_patterns = {\n",
    "        \"US\": {\"calls\": (8, 2), \"prescriptions\": (12, 3), \"samples\": (25, 5), \"expenses\": (150, 30)},\n",
    "        \"EU\": {\"calls\": (6, 1.5), \"prescriptions\": (9, 2), \"samples\": (18, 4), \"expenses\": (100, 20)},\n",
    "        \"APAC\": {\"calls\": (10, 3), \"prescriptions\": (15, 4), \"samples\": (30, 7), \"expenses\": (120, 25)},\n",
    "    }\n",
    "    \n",
    "    start_date = datetime(2024, 1, 1)\n",
    "    \n",
    "    for i in range(num_rows):\n",
    "        region = random.choice(regions)\n",
    "        pattern = regional_patterns[region]\n",
    "        \n",
    "        # Normal patterns (95% of data)\n",
    "        if random.random() > anomaly_rate:\n",
    "            calls = max(1, int(np.random.normal(pattern[\"calls\"][0], pattern[\"calls\"][1])))\n",
    "            prescriptions = max(0, int(np.random.normal(pattern[\"prescriptions\"][0], pattern[\"prescriptions\"][1])))\n",
    "            samples = max(0, int(np.random.normal(pattern[\"samples\"][0], pattern[\"samples\"][1])))\n",
    "            expenses = max(10, round(np.random.normal(pattern[\"expenses\"][0], pattern[\"expenses\"][1]), 2))\n",
    "            is_remote = random.random() < 0.3\n",
    "            call_type = random.choice(call_types)\n",
    "        else:\n",
    "            # Inject realistic anomalies (5% of data)\n",
    "            anomaly_type = random.choice([\"high_expense\", \"low_productivity\", \"unrealistic_prescriptions\"])\n",
    "            \n",
    "            if anomaly_type == \"high_expense\":\n",
    "                # Excessive expenses with low output (potential fraud)\n",
    "                calls = max(1, int(np.random.normal(pattern[\"calls\"][0] * 0.5, 1)))\n",
    "                prescriptions = max(0, int(np.random.normal(pattern[\"prescriptions\"][0] * 0.4, 1)))\n",
    "                samples = max(0, int(np.random.normal(pattern[\"samples\"][0] * 0.6, 2)))\n",
    "                expenses = round(pattern[\"expenses\"][0] * random.uniform(2.5, 4.0), 2)  # 2.5-4x normal\n",
    "                is_remote = False\n",
    "                call_type = \"promotional\"\n",
    "            \n",
    "            elif anomaly_type == \"low_productivity\":\n",
    "                # Many calls but few results (training need)\n",
    "                calls = int(pattern[\"calls\"][0] * random.uniform(1.8, 2.5))\n",
    "                prescriptions = max(0, int(pattern[\"prescriptions\"][0] * random.uniform(0.2, 0.4)))\n",
    "                samples = int(pattern[\"samples\"][0] * random.uniform(0.3, 0.5))\n",
    "                expenses = round(pattern[\"expenses\"][0] * random.uniform(1.2, 1.5), 2)\n",
    "                is_remote = random.random() < 0.5\n",
    "                call_type = \"follow_up\"\n",
    "            \n",
    "            else:  # unrealistic_prescriptions\n",
    "                # Suspiciously high prescription rate (investigation needed)\n",
    "                calls = max(1, int(np.random.normal(pattern[\"calls\"][0], 1)))\n",
    "                prescriptions = int(pattern[\"prescriptions\"][0] * random.uniform(2.5, 4.0))\n",
    "                samples = int(pattern[\"samples\"][0] * random.uniform(1.5, 2.0))\n",
    "                expenses = round(pattern[\"expenses\"][0] * random.uniform(0.8, 1.2), 2)\n",
    "                is_remote = False\n",
    "                call_type = \"promotional\"\n",
    "        \n",
    "        days_offset = random.randint(0, 180)\n",
    "        call_date = start_date + timedelta(days=days_offset)\n",
    "        \n",
    "        data.append((\n",
    "            f\"REP{i % 50:03d}\",  # 50 unique reps\n",
    "            region,\n",
    "            call_date,\n",
    "            calls,\n",
    "            prescriptions,\n",
    "            samples,\n",
    "            expenses,\n",
    "            is_remote,\n",
    "            call_type\n",
    "        ))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate data\n",
    "print(\"üîÑ Generating sales rep activity data...\")\n",
    "field_force_data = generate_field_force_data(num_rows=1000, anomaly_rate=0.05)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"rep_id\", StringType(), False),\n",
    "    StructField(\"region\", StringType(), False),\n",
    "    StructField(\"call_date\", DateType(), False),\n",
    "    StructField(\"calls_made\", IntegerType(), False),\n",
    "    StructField(\"prescriptions_generated\", IntegerType(), False),\n",
    "    StructField(\"samples_distributed\", IntegerType(), False),\n",
    "    StructField(\"expenses\", DoubleType(), False),\n",
    "    StructField(\"is_remote\", BooleanType(), False),\n",
    "    StructField(\"call_type\", StringType(), False),\n",
    "])\n",
    "\n",
    "df_sales = spark.createDataFrame(field_force_data, schema)\n",
    "\n",
    "print(\"\\nüìä Sample of field force activity data:\")\n",
    "df_sales.orderBy(\"call_date\").show(10, truncate=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Generated {df_sales.count()} rows with ~5% injected anomalies\")\n",
    "print(f\"   Regions: {df_sales.select('region').distinct().count()}\")\n",
    "print(f\"   Unique reps: {df_sales.select('rep_id').distinct().count()}\")\n",
    "print(f\"   Date range: {df_sales.agg(F.min('call_date'), F.max('call_date')).first()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to table for training\n",
    "catalog = spark.sql(\"SELECT current_catalog()\").first()[0]\n",
    "schema_name = \"dqx_demo\"\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema_name}\")\n",
    "\n",
    "table_name = f\"{catalog}.{schema_name}.field_force_activity\"\n",
    "df_sales.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(f\"‚úÖ Data saved to: {table_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Auto-Discovery vs Manual Tuning (12 min)\n",
    "\n",
    "### 2.1 Auto-Discovery (Zero Configuration)\n",
    "\n",
    "Let's start with zero configuration - DQX will automatically select columns and detect segments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with ZERO configuration (auto-discovery)\n",
    "print(\"üéØ Training with AUTO-DISCOVERY (zero config)...\\\\n\")\n",
    "\n",
    "model_uri_auto = train(\n",
    "    df=spark.table(table_name),\n",
    "    # NO columns specified - auto-discovered!\n",
    "    # NO segments specified - auto-discovered!\n",
    "    # Model name auto-generated!\n",
    "    registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    ")\n",
    "\n",
    "print(f\"\\\\n‚úÖ Auto-discovery model trained!\")\n",
    "print(f\"   Model URI: {model_uri_auto}\")\n",
    "\n",
    "# Check what was auto-discovered\n",
    "registry_df = spark.table(f\"{catalog}.{schema_name}.anomaly_model_registry\")\n",
    "auto_model = registry_df.filter(F.col(\"model_uri\") == model_uri_auto).first()\n",
    "\n",
    "print(f\"\\\\nüìã Auto-Discovered Configuration:\")\n",
    "print(f\"   Columns: {auto_model['columns']}\")\n",
    "print(f\"   Segments: {auto_model['segment_by']}\")\n",
    "print(f\"   Column types: {auto_model['column_types']}\")\n",
    "print(f\"\\\\nüí° DQX prioritized: numeric > boolean > categorical > datetime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score with auto-discovered model\n",
    "checks_auto = [\n",
    "    has_no_anomalies(\n",
    "        score_threshold=0.5,\n",
    "        registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    "    )\n",
    "]\n",
    "\n",
    "df_scored_auto = dq_engine.apply_checks_by_metadata(df_sales, checks_auto)\n",
    "anomalies_auto = df_scored_auto.filter(F.col(\"anomaly_score\") >= 0.5)\n",
    "\n",
    "print(f\"\\\\n‚ö†Ô∏è  Auto-discovery found {anomalies_auto.count()} anomalies:\\\\n\")\n",
    "anomalies_auto.orderBy(F.col(\"anomaly_score\").desc()).select(\n",
    "    \"rep_id\", \"region\", \"calls_made\", \"prescriptions_generated\", \"expenses\",\n",
    "    F.round(\"anomaly_score\", 3).alias(\"score\")\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Manual Column Selection & Parameter Tuning\n",
    "\n",
    "Now let's manually select specific columns and tune hyperparameters for better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with MANUAL configuration and tuned parameters\n",
    "print(\"üéØ Training with MANUAL tuning...\\\\n\")\n",
    "\n",
    "model_uri_manual = train(\n",
    "    df=spark.table(table_name),\n",
    "    columns=[\"calls_made\", \"prescriptions_generated\", \"samples_distributed\", \"expenses\"],  # Manual selection\n",
    "    model_name=\"field_force_tuned\",\n",
    "    params=AnomalyParams(\n",
    "        isolation_forest=IsolationForestConfig(\n",
    "            contamination=0.05,  # Expected 5% anomaly rate (matches our data)\n",
    "            n_estimators=150,    # More trees for stability (default 100)\n",
    "            max_samples=512,     # Subsample size for speed\n",
    "            random_state=42      # Reproducibility\n",
    "        ),\n",
    "        sample_fraction=1.0,     # Use all data (no sampling)\n",
    "        max_rows=None            # No row limit\n",
    "    ),\n",
    "    registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    ")\n",
    "\n",
    "print(f\"\\\\n‚úÖ Manual tuned model trained!\")\n",
    "print(f\"   Model URI: {model_uri_manual}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score with tuned model\n",
    "checks_manual = [\n",
    "    has_no_anomalies(\n",
    "        model=\"field_force_tuned\",\n",
    "        score_threshold=0.5,\n",
    "        registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    "    )\n",
    "]\n",
    "\n",
    "df_scored_manual = dq_engine.apply_checks_by_metadata(df_sales, checks_manual)\n",
    "anomalies_manual = df_scored_manual.filter(F.col(\"anomaly_score\") >= 0.5)\n",
    "\n",
    "print(f\"\\\\n‚ö†Ô∏è  Manual tuned model found {anomalies_manual.count()} anomalies:\\\\n\")\n",
    "anomalies_manual.orderBy(F.col(\"anomaly_score\").desc()).select(\n",
    "    \"rep_id\", \"region\", \"calls_made\", \"prescriptions_generated\", \"expenses\",\n",
    "    F.round(\"anomaly_score\", 3).alias(\"score\")\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model Comparison\n",
    "\n",
    "Let's compare the auto-discovered vs manually tuned models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print(\"üìä Model Comparison:\\\\n\")\n",
    "comparison = registry_df.filter(\n",
    "    F.col(\"model_uri\").isin([model_uri_auto, model_uri_manual])\n",
    ").select(\n",
    "    \"model_name\",\n",
    "    \"columns\",\n",
    "    \"training_rows\",\n",
    "    \"metrics\"\n",
    ").collect()\n",
    "\n",
    "for model in comparison:\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Model: {model['model_name']}\")\n",
    "    print(f\"Columns: {model['columns']}\")\n",
    "    print(f\"Training rows: {model['training_rows']}\")\n",
    "    print(f\"Metrics: {model['metrics']}\")\n",
    "    print()\n",
    "\n",
    "print(\"üí° Tuning Tips:\")\n",
    "print(\"   - contamination: Set to expected anomaly rate (0.01-0.1)\")\n",
    "print(\"   - n_estimators: More trees = more stable (100-200)\")\n",
    "print(\"   - max_samples: Smaller = faster, larger = more accurate (256-1024)\")\n",
    "print(\"   - Start with auto-discovery, then refine based on domain knowledge\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Segment-Based Monitoring (8 min)\n",
    "\n",
    "Different regions have different patterns. Train per-region models for accurate baselines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with regional segmentation\n",
    "print(\"üåç Training region-specific anomaly models...\\\\n\")\n",
    "\n",
    "model_uri_segmented = train(\n",
    "    df=spark.table(table_name),\n",
    "    columns=[\"calls_made\", \"prescriptions_generated\", \"samples_distributed\", \"expenses\"],\n",
    "    segment_by=[\"region\"],  # Train separate model per region\n",
    "    model_name=\"field_force_regional\",\n",
    "    params=AnomalyParams(\n",
    "        isolation_forest=IsolationForestConfig(contamination=0.05, n_estimators=150, random_state=42)\n",
    "    ),\n",
    "    registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    ")\n",
    "\n",
    "print(f\"\\\\n‚úÖ Regional models trained!\")\n",
    "print(\"   DQX automatically trained 3 models (US, EU, APAC)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare regional baselines\n",
    "regional_models = spark.table(f\"{catalog}.{schema_name}.anomaly_model_registry\").filter(\n",
    "    F.col(\"model_name\") == \"field_force_regional\"\n",
    ")\n",
    "\n",
    "print(\"üìä Regional Model Baselines:\\\\n\")\n",
    "for row in regional_models.select(\"segment_values\", \"training_rows\", \"baseline_stats\").collect():\n",
    "    region = row['segment_values']['region']\n",
    "    print(f\"Region: {region}\")\n",
    "    print(f\"  Training rows: {row['training_rows']}\")\n",
    "    print(f\"  Baseline stats: {row['baseline_stats']}\")\n",
    "    print()\n",
    "\n",
    "print(\"üîç Notice: Each region has different baselines!\")\n",
    "print(\"   US: Higher expenses ($150 avg)\")\n",
    "print(\"   EU: Lower expenses ($100 avg)\")\n",
    "print(\"   APAC: Highest volume (10 calls, 15 prescriptions avg)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score with regional models (automatic routing)\n",
    "checks_regional = [\n",
    "    has_no_anomalies(\n",
    "        model=\"field_force_regional\",\n",
    "        score_threshold=0.5,\n",
    "        registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    "    )\n",
    "]\n",
    "\n",
    "df_scored_regional = dq_engine.apply_checks_by_metadata(df_sales, checks_regional)\n",
    "\n",
    "print(\"‚ö†Ô∏è  Regional anomalies by region:\\\\n\")\n",
    "df_scored_regional.filter(F.col(\"anomaly_score\") >= 0.5).groupBy(\"region\").agg(\n",
    "    F.count(\"*\").alias(\"anomaly_count\"),\n",
    "    F.avg(\"anomaly_score\").alias(\"avg_score\"),\n",
    "    F.max(\"anomaly_score\").alias(\"max_score\")\n",
    ").orderBy(\"region\").show()\n",
    "\n",
    "print(\"\\\\nüìã Top regional anomalies:\")\n",
    "df_scored_regional.filter(F.col(\"anomaly_score\") >= 0.5).orderBy(\n",
    "    F.col(\"anomaly_score\").desc()\n",
    ").select(\n",
    "    \"rep_id\", \"region\", \"calls_made\", \"prescriptions_generated\", \"expenses\",\n",
    "    F.round(\"anomaly_score\", 3).alias(\"score\")\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Feature Contributions & Root Cause (8 min)\n",
    "\n",
    "**Why is a record anomalous?** Use SHAP to understand which columns drove the anomaly score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score with SHAP-based feature contributions\n",
    "checks_with_contrib = [\n",
    "    has_no_anomalies(\n",
    "        model=\"field_force_regional\",\n",
    "        score_threshold=0.5,\n",
    "        include_contributions=True,  # Enable SHAP explanations\n",
    "        registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    "    )\n",
    "]\n",
    "\n",
    "df_with_contrib = dq_engine.apply_checks_by_metadata(df_sales, checks_with_contrib)\n",
    "\n",
    "print(\"üîç Top Anomalies with Feature Contributions (SHAP):\\\\n\")\n",
    "anomalies_contrib = df_with_contrib.filter(\n",
    "    F.col(\"anomaly_score\") >= 0.5\n",
    ").orderBy(F.col(\"anomaly_score\").desc()).limit(10)\n",
    "\n",
    "anomalies_contrib.select(\n",
    "    \"rep_id\", \"region\",\n",
    "    \"calls_made\", \"prescriptions_generated\", \"samples_distributed\", \"expenses\",\n",
    "    F.round(\"anomaly_score\", 3).alias(\"score\"),\n",
    "    \"anomaly_contributions\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze contribution patterns for root cause\n",
    "print(\"üìä Root Cause Analysis:\\\\n\")\n",
    "\n",
    "top_anomaly = anomalies_contrib.first()\n",
    "print(f\"üî∏ Top Anomaly: REP={top_anomaly['rep_id']}, Region={top_anomaly['region']}\")\n",
    "print(f\"   Score: {top_anomaly['anomaly_score']:.3f}\")\n",
    "print(f\"   Values:\")\n",
    "print(f\"     ‚Ä¢ calls_made: {top_anomaly['calls_made']}\")\n",
    "print(f\"     ‚Ä¢ prescriptions: {top_anomaly['prescriptions_generated']}\")\n",
    "print(f\"     ‚Ä¢ samples: {top_anomaly['samples_distributed']}\")\n",
    "print(f\"     ‚Ä¢ expenses: ${top_anomaly['expenses']:.2f}\")\n",
    "print(f\"\\\\n   üìà Feature Contributions (SHAP):\")\n",
    "\n",
    "if top_anomaly['anomaly_contributions']:\n",
    "    sorted_contribs = sorted(\n",
    "        top_anomaly['anomaly_contributions'].items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    for feature, contribution in sorted_contribs:\n",
    "        print(f\"      {feature:30s}: {contribution:.3f} ({contribution*100:.1f}%)\")\n",
    "\n",
    "print(\"\\\\nüí° Business Interpretation Examples:\")\n",
    "print(\"   ‚Ä¢ High 'expenses' contribution ‚Üí Potential fraud or policy violation\")\n",
    "print(\"   ‚Ä¢ High 'calls_made' + low 'prescriptions' ‚Üí Training need or territory issue\")\n",
    "print(\"   ‚Ä¢ High 'prescriptions' contribution ‚Üí Unrealistic claims to investigate\")\n",
    "print(\"   ‚Ä¢ Balanced contributions ‚Üí Multivariate anomaly (multiple factors)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Drift Detection & Retraining (6 min)\n",
    "\n",
    "Data distributions change over time. DQX can detect when your model becomes stale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate drift: New patterns (more remote work, lower expenses post-policy change)\n",
    "def generate_drifted_data(num_rows=200):\n",
    "    \"\"\"Generate Q3 data with shifted distribution (post-policy change).\"\"\"\n",
    "    data = []\n",
    "    regions = [\"US\", \"EU\", \"APAC\"]\n",
    "    call_types = [\"promotional\", \"educational\", \"follow_up\"]\n",
    "    \n",
    "    # NEW PATTERNS: More remote work, lower expenses, similar productivity\n",
    "    new_patterns = {\n",
    "        \"US\": {\"calls\": (9, 2), \"prescriptions\": (12, 3), \"samples\": (20, 4), \"expenses\": (100, 20)},  # -33% expenses\n",
    "        \"EU\": {\"calls\": (7, 1.5), \"prescriptions\": (9, 2), \"samples\": (15, 3), \"expenses\": (70, 15)},   # -30% expenses\n",
    "        \"APAC\": {\"calls\": (11, 3), \"prescriptions\": (15, 4), \"samples\": (25, 6), \"expenses\": (85, 20)}, # -29% expenses\n",
    "    }\n",
    "    \n",
    "    start_date = datetime(2024, 7, 1)  # Q3 data\n",
    "    \n",
    "    for i in range(num_rows):\n",
    "        region = random.choice(regions)\n",
    "        pattern = new_patterns[region]\n",
    "        \n",
    "        calls = max(1, int(np.random.normal(pattern[\"calls\"][0], pattern[\"calls\"][1])))\n",
    "        prescriptions = max(0, int(np.random.normal(pattern[\"prescriptions\"][0], pattern[\"prescriptions\"][1])))\n",
    "        samples = max(0, int(np.random.normal(pattern[\"samples\"][0], pattern[\"samples\"][1])))\n",
    "        expenses = max(10, round(np.random.normal(pattern[\"expenses\"][0], pattern[\"expenses\"][1]), 2))\n",
    "        is_remote = random.random() < 0.7  # 70% remote now (was 30%)\n",
    "        call_type = random.choice(call_types)\n",
    "        \n",
    "        days_offset = random.randint(0, 90)\n",
    "        call_date = start_date + timedelta(days=days_offset)\n",
    "        \n",
    "        data.append((f\"REP{i % 50:03d}\", region, call_date, calls, prescriptions, samples, expenses, is_remote, call_type))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate and compare\n",
    "drifted_data = generate_drifted_data(num_rows=200)\n",
    "df_drifted = spark.createDataFrame(drifted_data, schema)\n",
    "\n",
    "print(\"üìä Original vs Drifted Data Comparison:\\\\n\")\n",
    "print(\"Original (Q1-Q2 2024):\") \n",
    "df_sales.agg(\n",
    "    F.avg(\"expenses\").alias(\"avg_expenses\"),\n",
    "    F.avg(F.col(\"is_remote\").cast(\"int\")).alias(\"remote_rate\")\n",
    ").show()\n",
    "\n",
    "print(\"Drifted (Q3 2024 - post policy change):\")\n",
    "df_drifted.agg(\n",
    "    F.avg(\"expenses\").alias(\"avg_expenses\"),\n",
    "    F.avg(F.col(\"is_remote\").cast(\"int\")).alias(\"remote_rate\")\n",
    ").show()\n",
    "\n",
    "print(\"‚úÖ Distribution shifted:\")\n",
    "print(\"   ‚Ä¢ Expenses: -30% (policy change)\")\n",
    "print(\"   ‚Ä¢ Remote work: +133% (70% vs 30%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score drifted data with drift detection enabled\n",
    "checks_with_drift = [\n",
    "    has_no_anomalies(\n",
    "        model=\"field_force_regional\",\n",
    "        drift_threshold=3.0,  # Z-score threshold (default)\n",
    "        registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"üîç Scoring drifted data with drift detection...\\\\n\")\n",
    "print(\"‚ö†Ô∏è  Watch for drift warnings in output!\\\\n\")\n",
    "\n",
    "df_drift_scored = dq_engine.apply_checks_by_metadata(df_drifted, checks_with_drift)\n",
    "\n",
    "print(\"\\\\n‚ÑπÔ∏è  Drift warnings appear as UserWarnings like:\")\n",
    "print(\"   'Data drift detected in columns: expenses (drift score: 4.2)'\")\n",
    "print(\"   'Model may be stale. Retrain using: train(...)'\")\n",
    "print(\"\\\\nüí° Drift score > 3.0 ‚Üí Significant distribution shift, retrain recommended\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with combined data\n",
    "df_combined = df_sales.union(df_drifted)\n",
    "\n",
    "print(\"üîÑ Retraining model with combined data (old + new patterns)...\\\\n\")\n",
    "\n",
    "model_uri_retrained = train(\n",
    "    df=df_combined,\n",
    "    columns=[\"calls_made\", \"prescriptions_generated\", \"samples_distributed\", \"expenses\"],\n",
    "    segment_by=[\"region\"],\n",
    "    model_name=\"field_force_regional\",  # Same name = new version\n",
    "    params=AnomalyParams(\n",
    "        isolation_forest=IsolationForestConfig(contamination=0.05, n_estimators=150, random_state=42)\n",
    "    ),\n",
    "    registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    ")\n",
    "\n",
    "print(\"\\\\n‚úÖ Model retrained!\")\n",
    "print(\"   ‚Ä¢ Old model automatically archived\")\n",
    "print(\"   ‚Ä¢ New model active and includes both historical and recent patterns\")\n",
    "print(\"   ‚Ä¢ Baseline updated to reflect new expense policy and remote work rates\")\n",
    "print(\"\\\\nüí° Best Practice: Set up drift monitoring in production, retrain monthly/quarterly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Production Integration (6 min)\n",
    "\n",
    "Integrate anomaly detection into your DQX workflows for automated monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine anomaly detection with traditional DQ checks\n",
    "checks_combined = [\n",
    "    # Traditional data quality checks\n",
    "    is_not_null(columns=[\"rep_id\", \"region\", \"call_date\"]),\n",
    "    is_in_range(column=\"calls_made\", min_value=0, max_value=50),\n",
    "    is_in_range(column=\"expenses\", min_value=0, max_value=1000),\n",
    "    \n",
    "    # ML-based anomaly detection with explanations\n",
    "    has_no_anomalies(\n",
    "        model=\"field_force_regional\",\n",
    "        score_threshold=0.5,\n",
    "        include_contributions=True,\n",
    "        drift_threshold=3.0,\n",
    "        registry_table=f\"{catalog}.{schema_name}.anomaly_model_registry\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Apply all checks together\n",
    "df_full_dq = dq_engine.apply_checks_by_metadata(df_sales, checks_combined)\n",
    "\n",
    "# Summary\n",
    "print(\"üìä Full Data Quality Summary:\\\\n\")\n",
    "total_rows = df_full_dq.count()\n",
    "anomalies_found = df_full_dq.filter(F.col(\"anomaly_score\") >= 0.5).count()\n",
    "\n",
    "# Note: Traditional check condition columns would have specific names based on implementation\n",
    "print(f\"Total Rows: {total_rows}\")\n",
    "print(f\"Anomalies Detected: {anomalies_found}\")\n",
    "print(f\"Clean Records: {total_rows - anomalies_found}\")\n",
    "print(f\"\\\\n‚úÖ All checks applied in single pass!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarantine anomalies for review\n",
    "quarantine_table = f\"{catalog}.{schema_name}.field_force_quarantine\"\n",
    "\n",
    "quarantine_df = df_full_dq.filter(\n",
    "    F.col(\"anomaly_score\") >= 0.5\n",
    ").select(\n",
    "    \"*\",\n",
    "    F.current_timestamp().alias(\"quarantine_timestamp\"),\n",
    "    F.lit(\"anomaly_detected\").alias(\"quarantine_reason\")\n",
    ")\n",
    "\n",
    "quarantine_df.write.mode(\"overwrite\").saveAsTable(quarantine_table)\n",
    "\n",
    "print(f\"‚úÖ Quarantined {quarantine_df.count()} anomalies to: {quarantine_table}\")\n",
    "print(\"\\\\nüìã Quarantine Summary by Region:\")\n",
    "spark.table(quarantine_table).groupBy(\"region\").agg(\n",
    "    F.count(\"*\").alias(\"count\"),\n",
    "    F.avg(\"anomaly_score\").alias(\"avg_score\"),\n",
    "    F.max(\"anomaly_score\").alias(\"max_score\")\n",
    ").orderBy(\"region\").show()\n",
    "\n",
    "print(\"\\\\nüí° Quarantine Workflow:\")\n",
    "print(\"   1. Anomalies automatically sent to quarantine table\")\n",
    "print(\"   2. Review team investigates using anomaly_contributions\")\n",
    "print(\"   3. Confirmed issues ‚Üí escalate to appropriate team\")\n",
    "print(\"   4. False positives ‚Üí retune model or adjust threshold\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAML Configuration for Production\n",
    "\n",
    "For automated workflows, define checks in YAML:\n",
    "\n",
    "```yaml\n",
    "run_configs:\n",
    "  - name: field_force_monitoring\n",
    "    input_config:\n",
    "      location: catalog.schema.field_force_activity\n",
    "    \n",
    "    # Traditional checks\n",
    "    quality_checks:\n",
    "      - function: is_not_null\n",
    "        arguments:\n",
    "          columns: [rep_id, region, call_date]\n",
    "      - function: is_in_range\n",
    "        arguments:\n",
    "          column: calls_made\n",
    "          min_value: 0\n",
    "          max_value: 50\n",
    "      - function: is_in_range\n",
    "        arguments:\n",
    "          column: expenses\n",
    "          min_value: 0\n",
    "          max_value: 1000\n",
    "    \n",
    "    # Anomaly detection\n",
    "    anomaly_config:\n",
    "      columns: [calls_made, prescriptions_generated, samples_distributed, expenses]\n",
    "      segment_by: [region]\n",
    "      model_name: field_force_regional\n",
    "      registry_table: catalog.schema.anomaly_model_registry\n",
    "      params:\n",
    "        isolation_forest:\n",
    "          contamination: 0.05\n",
    "          n_estimators: 150\n",
    "          random_state: 42\n",
    "        sample_fraction: 1.0\n",
    "    \n",
    "    # Quarantine configuration\n",
    "    quarantine_config:\n",
    "      enabled: true\n",
    "      table: catalog.schema.field_force_quarantine\n",
    "      \n",
    "    # Output configuration\n",
    "    output_config:\n",
    "      location: catalog.schema.field_force_clean\n",
    "      save_mode: overwrite\n",
    "```\n",
    "\n",
    "**Run with:**\n",
    "```bash\n",
    "# Train model (one-time or scheduled)\n",
    "databricks bundle run anomaly_trainer\n",
    "\n",
    "# Run quality checks (scheduled, e.g., daily)\n",
    "databricks bundle run quality_checker\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Summary\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. ‚úÖ **Auto-Discovery vs Manual Tuning** - Start with zero-config, refine with domain knowledge\n",
    "2. ‚úÖ **Parameter Tuning** - contamination, n_estimators, max_samples for better performance\n",
    "3. ‚úÖ **Segment-Based Monitoring** - Regional baselines prevent false positives (US vs EU vs APAC)\n",
    "4. ‚úÖ **Feature Contributions** - SHAP-based root cause analysis for investigation\n",
    "5. ‚úÖ **Drift Detection** - Automated signals for when to retrain models\n",
    "6. ‚úÖ **Multi-Type Features** - Numeric, categorical, datetime, boolean all work together\n",
    "7. ‚úÖ **Production Integration** - DQEngine + YAML workflows + quarantine handling\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Start simple**: `train(df)` with auto-discovery, then refine\n",
    "- **Tune parameters**: Set contamination to expected anomaly rate, increase n_estimators for stability\n",
    "- **Use segments**: Different baselines for different groups prevent false positives\n",
    "- **Enable contributions**: Root cause analysis is critical for business value\n",
    "- **Monitor drift**: Set up drift detection for automated retraining signals\n",
    "- **Combine checks**: Anomaly detection complements traditional DQ rules\n",
    "- **Quarantine workflow**: Automate review process with explanations\n",
    "\n",
    "### Model Comparison Results:\n",
    "\n",
    "| Approach | Columns | Segments | Tuning | Use Case |\n",
    "|----------|---------|----------|--------|----------|\n",
    "| Auto-discovery | Auto (priority-based) | Auto (if applicable) | Default | Quick start, exploration |\n",
    "| Manual tuned | Hand-picked | Manual | Custom hyperparameters | Production, refined monitoring |\n",
    "| Regional | Hand-picked | By region | Tuned contamination | Multi-region with different baselines |\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Apply to your data**: `train(df=spark.table(\"your_table\"))`\n",
    "2. **Set up YAML workflows**: Automate training and checking\n",
    "3. **Integrate quarantine**: Build review process with feature contributions\n",
    "4. **Schedule retraining**: Weekly/monthly based on drift monitoring\n",
    "5. **Monitor metrics**: Track anomaly rates, drift scores, false positive rates\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [DQX Anomaly Detection Documentation](https://databrickslabs.github.io/dqx/guide/anomaly_detection)\n",
    "- [API Reference](https://databrickslabs.github.io/dqx/reference/quality_checks#has_no_anomalies)\n",
    "- [GitHub Repository](https://github.com/databrickslabs/dqx)\n",
    "\n",
    "---\n",
    "\n",
    "**Questions? Feedback?** Open an issue on GitHub or contact the DQX team!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè• Pharmaceutical Field Force Effectiveness - Anomaly Detection Demo\n",
    "\n",
    "##Business Context\n",
    "\n",
    "**Scenario**: Monitor sales rep performance across regions to detect unusual patterns that may indicate:\n",
    "- Expense fraud or policy violations\n",
    "- Territory coverage issues\n",
    "- Unrealistic prescription claims\n",
    "- Training needs or process gaps\n",
    "\n",
    "**Data**: Sales rep daily activity including calls, prescriptions generated, samples distributed, and expenses\n",
    "\n",
    "## What You'll Learn (30-45 min)\n",
    "\n",
    "1. **Auto-Discovery**: Zero-config model training\n",
    "2. **Segment-Based Monitoring**: Regional baselines (US vs EU vs APAC)\n",
    "3. **Feature Contributions**: Root cause analysis for anomalies\n",
    "4. **Drift Detection**: When to retrain models\n",
    "5. **Multi-Type Features**: Numeric, categorical, datetime, boolean\n",
    "6. **Production Integration**: DQEngine and YAML workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Setup & Data Generation (5 min)\n",
    "\n",
    "First, install DQX with anomaly support if not already installed:\n",
    "```bash\n",
    "%pip install databricks-labs-dqx[anomaly]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from databricks.labs.dqx.anomaly import train, has_no_anomalies, AnomalyParams\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "# Initialize\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "ws = WorkspaceClient()\n",
    "dq_engine = DQEngine(ws)\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"   Spark version: {spark.version}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
