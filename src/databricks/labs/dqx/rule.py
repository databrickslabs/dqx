import abc
import logging
from enum import Enum
from dataclasses import dataclass, field
import functools as ft
from typing import Any
from collections.abc import Callable
from datetime import datetime
from pyspark.sql import Column, DataFrame
import pyspark.sql.functions as F
from databricks.labs.dqx.utils import get_column_as_string

logger = logging.getLogger(__name__)


CHECK_FUNC_REGISTRY: dict[str, str] = {}


def register_rule(rule_type: str) -> Callable:
    def wrapper(func: Callable) -> Callable:
        CHECK_FUNC_REGISTRY[func.__name__] = rule_type
        return func

    return wrapper


class Criticality(Enum):
    """Enum class to represent criticality of the check."""

    WARN = "warn"
    ERROR = "error"


class DefaultColumnNames(Enum):
    """Enum class to represent columns in the dataframe that will be used for error and warning reporting."""

    ERRORS = "_errors"
    WARNINGS = "_warnings"


class ColumnArguments(Enum):
    """Enum class that is used as input parsing for custom column naming."""

    ERRORS = "errors"
    WARNINGS = "warnings"


@dataclass(frozen=True)
class ExtraParams:
    """Class to represent extra parameters for DQEngine."""

    reporting_column_names: dict[str, str] = field(default_factory=dict)
    run_time: datetime = datetime.now()
    user_metadata: dict[str, str] = field(default_factory=dict)


@dataclass(frozen=True)
class DQRule(abc.ABC):
    """Represents a data quality rule that applies a quality check function to column(s) or
    column expression(s). This class includes the following attributes:
    * `check_func` - The function used to perform the quality check.
    * `name` (optional) - A custom name for the check; autogenerated if not provided.
    * `criticality` (optional) - Defines the severity level of the check:
        - `error`: Critical issues.
        - `warn`: Potential issues.
    * `column` (optional) - A single column to which the check function is applied.
    * `filter` (optional) - A filter expression to apply the check only to rows meeting specific conditions.
    * `check_func_args` (optional) - Positional arguments for the check function (excluding `column`).
    * `check_func_kwargs` (optional) - Keyword arguments for the check function (excluding `column`).
    * `user_metadata` (optional) - User-defined key-value pairs added to metadata generated by the check.
    """

    check_func: Callable
    name: str = ""
    criticality: str = Criticality.ERROR.value
    column: str | Column | None = None
    filter: str | None = None
    check_func_args: list[Any] = field(default_factory=list)
    check_func_kwargs: dict[str, Any] = field(default_factory=dict)
    user_metadata: dict[str, str] | None = None

    @ft.cached_property
    def check_criticality(self) -> str:
        """Criticality of the check.

        :return: string describing criticality - `warn` or `error`.
        :raises ValueError: if criticality is invalid.
        """
        criticality = self.criticality
        if criticality not in {Criticality.WARN.value, Criticality.ERROR.value}:
            raise ValueError(
                f"Invalid 'criticality' value: '{criticality}'. "
                f"Expected '{Criticality.WARN.value}' or '{Criticality.ERROR.value}'. "
                f"Check details: {self.name}"
            )
        return criticality

    @ft.cached_property
    def columns_as_string_expr(self) -> Column:
        """Spark Column expression representing the column(s) as a string (not normalized).
        :return: A Spark Column object representing the column(s) as a string (not normalized).
        """
        return F.lit(None).cast("array<string>")


@dataclass(frozen=True)
class DQRowRule(DQRule):
    """
    Represents a row-level data quality rule that applies a quality check function to a column or column expression.
    Works with check functions that take a single column or no column as input.
    """

    def __post_init__(self):
        rule_type = CHECK_FUNC_REGISTRY.get(self.check_func.__name__)
        # must be a row-level rule or custom rule (not internally registered built-in rule)
        if rule_type and rule_type not in ("row"):
            raise ValueError(
                f"Function '{self.check_func.__name__}' is not a row-level rule. Use DQDatasetRule instead."
            )

        check = self._check  # validate function parameters
        object.__setattr__(self, "name", self.name if self.name else get_column_as_string(check, normalize=True))

    @ft.cached_property
    def columns_as_string_expr(self) -> Column:
        """Spark Column expression representing the column(s) as a string (not normalized).
        :return: A Spark Column object representing the column(s) as a string (not normalized).
        """
        if self.column is not None:
            return F.array(F.lit(get_column_as_string(self.column)))
        return super().columns_as_string_expr

    def apply(self) -> Column:
        """Spark Column expression representing the check condition.

        This expression returns a string value if the check evaluates to `true`,
        which serves as an error or warning message. If the check evaluates to `false`,
        it returns `null`. If a filter condition is provided, the check is applied
        only to rows that satisfy the condition.

        :return: A Spark Column object representing the check condition.
        """
        return self._check

    @ft.cached_property
    def _check(self) -> Column:
        # inject the column as first argument of the check function
        args = [self.column] if self.column is not None else []
        args.extend(self.check_func_args)
        return self.check_func(*args, **self.check_func_kwargs)


@dataclass(frozen=True)
class DQDatasetRule(DQRule):
    """
    Represents a dataset-level data quality rule that applies a quality check function to a column or
    column expression or list of columns depending on the check function.
    Either column or columns can be provided but not both.
    This class extends DQRule and includes the following attributes in addition:
    * `columns` - A single column to which the check function is applied.
    """

    columns: list[str | Column] | None = None  # some checks require list of columns

    def __post_init__(self):
        rule_type = CHECK_FUNC_REGISTRY.get(self.check_func.__name__)
        # must be a dataset-level rule or custom rule (not internally registered built-in rule)
        if rule_type and rule_type not in ("dataset"):
            raise ValueError(
                f"Function '{self.check_func.__name__}' is not a dataset-level rule. Use DQRowRule instead."
            )

        if self.column is not None and self.columns is not None:
            raise ValueError("Both 'column' and 'columns' cannot be provided at the same time.")

        check, _ = self._check  # validate function parameters
        object.__setattr__(self, "name", self.name if self.name else get_column_as_string(check, normalize=True))

    @ft.cached_property
    def columns_as_string_expr(self) -> Column:
        """Spark Column expression representing the column(s) as a string (not normalized).
        :return: A Spark Column object representing the column(s) as a string (not normalized).
        """
        if self.column is not None:
            return F.array(F.lit(get_column_as_string(self.column)))
        if self.columns is not None:
            return F.array(*[F.lit(get_column_as_string(column)) for column in self.columns])
        return super().columns_as_string_expr

    def apply(self, df: DataFrame, ref_dfs: dict[str, DataFrame] | None = None) -> tuple[Column, DataFrame]:
        condition, apply_func = self._check
        # every dataset-level rule must accept a DataFrame and Dictionary of reference DataFrames in the closure func
        # and return a condition and a DataFrame
        return condition, apply_func(df, ref_dfs)

    @ft.cached_property
    def _check(self) -> tuple[Column, Callable]:
        args: list = []
        # inject the column or columns as first argument of the check function
        if self.column is not None:
            args = [self.column]
        elif self.columns is not None:
            args = [self.columns]
        args.extend(self.check_func_args)

        # dataset-level checks must apply filter directly
        self.check_func_kwargs["row_filter"] = self.filter

        condition, apply_func = self.check_func(*args, **self.check_func_kwargs)
        return condition, apply_func


@dataclass(frozen=True)
class DQForEachColRule:
    """Represents a data quality rule that applies to a quality check function
    repeatedly on each specified column of the provided list of columns.
    This class includes the following attributes:
    * `columns` - A list of column names or expressions to which the check function should be applied.
    * `check_func` - The function used to perform the quality check.
    * `name` (optional) - A custom name for the check; autogenerated if not provided.
    * `criticality` - The severity level of the check:
        - `'warn'` for potential issues.
        - `'error'` for critical issues.
    * `filter` (optional) - A filter expression to apply the check only to rows meeting specific conditions.
    * `check_func_args` (optional) - Positional arguments for the check function (excluding column names).
    * `check_func_kwargs` (optional) - Keyword arguments for the check function (excluding column names).
    * `user_metadata` (optional) - User-defined key-value pairs added to metadata generated by the check.
    """

    columns: list[str | Column | list[str | Column]]
    check_func: Callable
    name: str = ""
    criticality: str = Criticality.ERROR.value
    filter: str | None = None
    check_func_args: list[Any] = field(default_factory=list)
    check_func_kwargs: dict[str, Any] = field(default_factory=dict)
    user_metadata: dict[str, str] | None = None

    def get_rules(self) -> list[DQRule]:
        """Build a list of rules for a set of columns.

        :return: list of dq rules
        """
        rules: list[DQRule] = []
        for column in self.columns:
            rule_type = CHECK_FUNC_REGISTRY.get(self.check_func.__name__, None)
            if rule_type == "dataset":
                rules.append(
                    DQDatasetRule(
                        column=column if not isinstance(column, list) else None,
                        columns=column if isinstance(column, list) else None,
                        check_func=self.check_func,
                        check_func_kwargs=self.check_func_kwargs,
                        check_func_args=self.check_func_args,
                        name=self.name,
                        criticality=self.criticality,
                        filter=self.filter,
                        user_metadata=self.user_metadata,
                    )
                )
            else:  # default to row-level rule
                rules.append(
                    DQRowRule(
                        column=column if not isinstance(column, list) else None,
                        check_func=self.check_func,
                        check_func_kwargs=self.check_func_kwargs,
                        check_func_args=self.check_func_args,
                        name=self.name,
                        criticality=self.criticality,
                        filter=self.filter,
                        user_metadata=self.user_metadata,
                    )
                )
        return rules


@dataclass(frozen=True)
class ChecksValidationStatus:
    """Class to represent the validation status."""

    _errors: list[str] = field(default_factory=list)

    def add_error(self, error: str):
        """Add an error to the validation status."""
        self._errors.append(error)

    def add_errors(self, errors: list[str]):
        """Add an error to the validation status."""
        self._errors.extend(errors)

    @property
    def has_errors(self) -> bool:
        """Check if there are any errors in the validation status."""
        return bool(self._errors)

    @property
    def errors(self) -> list[str]:
        """Get the list of errors in the validation status."""
        return self._errors

    def to_string(self) -> str:
        """Convert the validation status to a string."""
        if self.has_errors:
            return "\n".join(self._errors)
        return "No errors found"

    def __str__(self) -> str:
        """String representation of the ValidationStatus class."""
        return self.to_string()
