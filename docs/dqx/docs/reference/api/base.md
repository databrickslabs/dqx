---
sidebar_label: base
title: databricks.labs.dqx.base
---

## DQEngineBase Objects

```python
class DQEngineBase(abc.ABC)
```

#### ws

```python
@cached_property
def ws() -> WorkspaceClient
```

Cached property to verify and return the workspace client.

#### spark

```python
@cached_property
def spark() -> SparkSession
```

Cached property return the SparkSession.

## DQEngineCoreBase Objects

```python
class DQEngineCoreBase(DQEngineBase)
```

#### apply\_checks

```python
@abc.abstractmethod
def apply_checks(df: DataFrame,
                 checks: list[DQRule],
                 ref_dfs: dict[str, DataFrame] | None = None) -> DataFrame
```

Applies data quality checks to a given dataframe.

**Arguments**:

- `df`: dataframe to check
- `checks`: list of checks to apply to the dataframe. Each check is an instance of DQRule class.
- `ref_dfs`: reference dataframes to use in the checks, if applicable

**Returns**:

dataframe with errors and warning result columns

#### apply\_checks\_and\_split

```python
@abc.abstractmethod
def apply_checks_and_split(
    df: DataFrame,
    checks: list[DQRule],
    ref_dfs: dict[str, DataFrame] | None = None
) -> tuple[DataFrame, DataFrame]
```

Applies data quality checks to a given dataframe and split it into two (&quot;good&quot; and &quot;bad&quot;),

according to the data quality checks.

**Arguments**:

- `df`: dataframe to check
- `checks`: list of checks to apply to the dataframe. Each check is an instance of DQRule class.
- `ref_dfs`: reference dataframes to use in the checks, if applicable

**Returns**:

two dataframes - &quot;good&quot; which includes warning rows but no result columns, and &quot;data&quot; having
error and warning rows and corresponding result columns

#### apply\_checks\_by\_metadata\_and\_split

```python
@abc.abstractmethod
def apply_checks_by_metadata_and_split(
    df: DataFrame,
    checks: list[dict],
    custom_check_functions: dict[str, Any] | None = None,
    ref_dfs: dict[str, DataFrame] | None = None
) -> tuple[DataFrame, DataFrame]
```

Wrapper around `apply_checks_and_split` for use in the metadata-driven pipelines. The main difference

is how the checks are specified - instead of using functions directly, they are described as function name plus
arguments.

**Arguments**:

- `df`: dataframe to check
- `checks`: list of dictionaries describing checks. Each check is a dictionary consisting of following fields:
* `check` - Column expression to evaluate. This expression should return string value if it&#x27;s evaluated to true -
it will be used as an error/warning message, or `null` if it&#x27;s evaluated to `false`
* `name` - name that will be given to a resulting column. Autogenerated if not provided
* `criticality` (optional) - possible values are `error` (data going only into &quot;bad&quot; dataframe),
and `warn` (data is going into both dataframes)
- `df`0: dictionary with custom check functions (eg. `df`1globals()`df`1 of the calling module).
If not specified, then only built-in functions are used for the checks.
- `df`3: reference dataframes to use in the checks, if applicable

**Returns**:

two dataframes - &quot;good&quot; which includes warning rows but no result columns, and &quot;bad&quot; having
error and warning rows and corresponding result columns

#### apply\_checks\_by\_metadata

```python
@abc.abstractmethod
def apply_checks_by_metadata(
        df: DataFrame,
        checks: list[dict],
        custom_check_functions: dict[str, Any] | None = None,
        ref_dfs: dict[str, DataFrame] | None = None) -> DataFrame
```

Wrapper around `apply_checks` for use in the metadata-driven pipelines. The main difference

is how the checks are specified - instead of using functions directly, they are described as function name plus
arguments.

**Arguments**:

- `df`: dataframe to check
- `checks`: list of dictionaries describing checks. Each check is a dictionary consisting of following fields:
* `check` - Column expression to evaluate. This expression should return string value if it&#x27;s evaluated to true -
it will be used as an error/warning message, or `null` if it&#x27;s evaluated to `false`
* `name` - name that will be given to a resulting column. Autogenerated if not provided
* `criticality` (optional) - possible values are `error` (data going only into &quot;bad&quot; dataframe),
and `warn` (data is going into both dataframes)
- `df`0: dictionary with custom check functions (eg. `df`1globals()`df`1 of calling module).
If not specified, then only built-in functions are used for the checks.
- `df`3: reference dataframes to use in the checks, if applicable

**Returns**:

dataframe with errors and warning result columns

#### validate\_checks

```python
@staticmethod
@abc.abstractmethod
def validate_checks(
    checks: list[dict],
    custom_check_functions: dict[str, Any] | None = None
) -> ChecksValidationStatus
```

Validate the input dict to ensure they conform to expected structure and types.

Each check can be a dictionary. The function validates
the presence of required keys, the existence and callability of functions, and the types
of arguments passed to these functions.

**Arguments**:

- `checks`: List of checks to apply to the dataframe. Each check should be a dictionary.
- `custom_check_functions`: Optional dictionary with custom check functions.

**Returns**:

`ValidationStatus`: The validation status.

#### get\_invalid

```python
@abc.abstractmethod
def get_invalid(df: DataFrame) -> DataFrame
```

Get records that violate data quality checks (records with warnings and errors).
@param df: input DataFrame.
@return: dataframe with error and warning rows and corresponding result columns.

#### get\_valid

```python
@abc.abstractmethod
def get_valid(df: DataFrame) -> DataFrame
```

Get records that don&#x27;t violate data quality checks (records with warnings but no errors).
@param df: input DataFrame.
@return: dataframe with warning rows but no result columns.

#### load\_checks\_from\_local\_file

```python
@staticmethod
@abc.abstractmethod
def load_checks_from_local_file(filepath: str) -> list[dict]
```

Load checks (dq rules) from a file (json or yaml) in the local file system.

This does not require installation of DQX in the workspace.
The returning checks can be used as input for `apply_checks_by_metadata` function.

**Arguments**:

- `filepath`: path to a file containing the checks.

**Returns**:

list of dq rules

#### save\_checks\_in\_local\_file

```python
@staticmethod
@abc.abstractmethod
def save_checks_in_local_file(checks: list[dict], filepath: str)
```

Save checks (dq rules) to a file (yaml or json) in the local file system.

**Arguments**:

- `checks`: list of dq rules to save
- `filepath`: path to a file containing the checks.

