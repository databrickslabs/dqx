---
sidebar_position: 5
---

import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


# Loading and Storing Quality Checks

DQX offers methods to load and save checks to a file (YAML or JSON) or table in the local path, workspace, installation folder or Unity Catalog Volume file.
This allows you to save and load checks from various storage locations, making it easier to manage and reuse them across different workflows and environments.
You can also store checks in the code directly as list of `DQRule` object or `dict`, but this lead to scaling and maintenance challenges.

## Saving quality checks to a storage

You can save quality checks defined in code or generated by the [profiler](/docs/guide/data_profiling). to various storage locations.

<Admonition type="tip" title="Checks definition">
For the save methods to work, checks must be defined as a list of dictionaries.
If you create checks as a list of DQRule objects, you can convert them using the `serialize_checks` method, as described [here](/docs/reference/quality_rules/#converting-dqx-classes-to-metadata).
</Admonition>

<Tabs>
  <TabItem value="Python" label="Python" default>
    ```python
    from databricks.labs.dqx.engine import DQEngine
    from databricks.labs.dqx.config import (
      FileChecksStorageConfig,
      WorkspaceFileChecksStorageConfig,
      InstallationChecksStorageConfig,
      TableChecksStorageConfig,
      VolumeFileChecksStorageConfig
    )
    from databricks.sdk import WorkspaceClient

    dq_engine = DQEngine(WorkspaceClient())

    # Checks can be defined in code as below or generated by the profiler
    checks: list[dict] = yaml.safe_load("""
    - criticality: warn
      check:
        function: is_not_null_and_not_empty
        arguments:
          column: col3
     # ...
    """)

    # save checks as a YAML file in the local filesystem (overwrite the file)
    dq_engine.save_checks(checks, config=FileChecksStorageConfig(location="checks.yml"))

    # save checks as a YAML file in arbitrary workspace location (overwrite the file)
    dq_engine.save_checks(checks, config=WorkspaceFileChecksStorageConfig(location="/Shared/App1/checks.yml"))

    # save checks in a Delta table to "default" run config (append checks)
    dq_engine.save_checks(checks, config=TableChecksStorageConfig(location="dq.config.checks_table", mode="append"))

    # save checks in a Delta table with specific run config for filtering (overwrite checks)
    dq_engine.save_checks(checks, config=TableChecksStorageConfig(location="dq.config.checks_table", run_config_name="workflow_001", mode="overwrite"))

    # save checks as a YAML in a Unity Catalog volume location (overwrite the file)
    dq_engine.save_checks(checks, config=VolumeFileChecksStorageConfig(location="/Volumes/dq/config/checks_volume/App1/checks.yml"))

    # save checks as a YAML file or table defined in 'checks_location' in the run config
    # only works if DQX is installed in the workspace
    dq_engine.save_checks(checks, config=InstallationChecksStorageConfig(assume_user=True, run_config_name="default"))
    ```
  </TabItem>
  <TabItem value="Tool" label="Tool">
    When using the profiler workflow to generate quality check candidates, the checks are saved to the location specified in the `checks_location` field of the [configuration file](/docs/installation/#configuration-file).
  </TabItem>
</Tabs>

## Loading quality checks from a storage

You can use the loaded checks to apply quality checks using the methods described [here](/docs/guide/quality_checks).

<Admonition type="tip" title="Checks definition">
For the save methods to work, checks must be defined as a list of dictionaries.
If you create checks as a list of DQRule objects, you can convert them using the `serialize_checks` method, as described [here](/docs/reference/quality_rules/#converting-dqx-classes-to-metadata).
</Admonition>

<Tabs>
  <TabItem value="Python" label="Python" default>
    ```python
    from databricks.labs.dqx.engine import DQEngine
    from databricks.labs.dqx.config import (
      FileChecksStorageConfig,
      WorkspaceFileChecksStorageConfig,
      InstallationChecksStorageConfig,
      TableChecksStorageConfig,
      VolumeFileChecksStorageConfig
    )
    from databricks.sdk import WorkspaceClient

    dq_engine = DQEngine(WorkspaceClient())

    # load checks from a local path
    checks: list[dict] = dq_engine.load_checks(checks, config=FileChecksStorageConfig(location="checks.yml"))

    # load checks from arbitrary workspace location
    checks: list[dict] = dq_engine.load_checks(checks, config=WorkspaceFileChecksStorageConfig(location="/Shared/App1/checks.yml"))

    # load checks from a Delta table and default run config name
    checks: list[dict] = dq_engine.load_checks(checks, config=TableChecksStorageConfig(location="dq.config.checks_table"))

    # load checks from a Delta table with specific run config for filtering
    checks: list[dict] = dq_engine.load_checks(checks, config=TableChecksStorageConfig(location="dq.config.checks_table", run_config_name="workflow_001"))

    # load checks from a Unity Catalog volume
    checks: list[dict] = dq_engine.load_checks(checks, config=VolumeFileChecksStorageConfig(location="/Volumes/dq/config/checks_volume/App1/checks.yml"))

    # load checks from a file or table defined in the run config ('checks_location' field)
    # only works if DQX is installed in the workspace
    checks: list[dict] = dq_engine.load_checks(checks, config=InstallationChecksStorageConfig(run_config_name="default"))
    ```
  </TabItem>
  <TabItem value="Tool" label="Tool">
    When using the quality checker or e2e workflows to apply quality checks, they load checks from the `checks_location` field defined in the [configuration file](/docs/installation/#configuration-file).
  </TabItem>
</Tabs>
